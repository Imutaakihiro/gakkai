\chapter{データと手法}

本章では，本研究で使用したデータセットの概要，前処理手順，感情分類モデル，マルチタスク学習モデル，SHAP分析の手法について詳述する．

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{データセット}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{データセットの概要}
本研究では，福岡工業大学の授業評価システムにおける2018年度から2023年度までの6年間のデータを使用した．対象は9学科にわたり，授業数は3,268件である．自由記述の総件数は83,851件であり，各授業に対して平均25.2件の自由記述が付随している．このデータ規模は，機械学習モデルの構築および統計的分析を行う上で十分な量であると考えられる．

データセットの概要を表\ref{tab:dataset}に示す．

\begin{table}[t]
    \centering
    \caption{データセット概要}
    \label{tab:dataset}
    \resizebox{0.75\textwidth}{!}{
    \begin{tabular}{l r}
        \toprule
        項目 & 値 \\
        \midrule
        対象期間 & 2018年度〜2023年度（6年間） \\
        対象学科数 & 9 \\
        授業数 & 3,268 \\
        自由記述総件数 & 83,851 \\
        平均自由記述数/授業 & 25.2 \\
        自由記述の平均文字数 & 約41文字 \\
        \bottomrule
    \end{tabular}
    }
\end{table}

\subsection{授業評価アンケートの構成}
授業評価アンケートは，(1) 択一式質問の点数化による授業評価スコア，(2) 自由記述の2種類の情報から構成される．自由記述は以下の2つの質問からなる．

\begin{enumerate}
\item 先生に向けてこの授業の感想や学んだこと，意見や要望を記述してください
\item 次期履修者に向けて，この授業についてのアドバイスを記述してください
\end{enumerate}

授業評価スコアは4段階（1〜4点）であり，授業ごとに単一のスコアが付与される．授業評価スコアの平均値は3.459点（標準偏差0.216）であり，比較的高い評価に集中する傾向がある．一方，自由記述は授業単位で複数件存在するため，授業単位で集約して分析する必要がある．

\subsection{データの特性}
本データセットには以下の特性がある．第一に，授業評価スコアは順序尺度であり，等間隔性を仮定できない点である．第二に，自由記述の長さにばらつきがあり，短い記述（数文字）から長い記述（数百文字）まで存在する点である．第三に，自由記述には授業内容への感想，教員への要望，履修者へのアドバイスなど，多様な内容が含まれる点である．

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{前処理}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{テキストの正規化}
自由記述は，以下の前処理を施してモデル入力に適した形式へ変換した．

\begin{enumerate}
\item \textbf{Unicode正規化}: 全角・半角の統一，異体字の正規化を実施
\item \textbf{記号除去}: 絵文字，特殊記号，不要な空白を除去
\item \textbf{形態素解析}: MeCabを用いて日本語テキストをトークン化
\item \textbf{最大長制限}: BERTの入力長制限（512トークン）に合わせて切り詰め
\end{enumerate}

\subsection{トークナイザ}
本研究では，BERTの事前学習に用いられたトークナイザを使用した．具体的には，WordPieceアルゴリズムに基づくサブワード分割を採用している．日本語テキストに対しては，形態素解析による分かち書きを行った後にサブワード分割を適用した．

トークナイザの設定を表\ref{tab:tokenizer}に示す．

\begin{table}[t]
    \centering
    \caption{トークナイザの設定}
    \label{tab:tokenizer}
    \resizebox{0.7\textwidth}{!}{
    \begin{tabular}{l l}
        \toprule
        項目 & 設定値 \\
        \midrule
        最大トークン長 & 512 \\
        語彙サイズ & 32,000 \\
        特殊トークン & [CLS], [SEP], [PAD], [UNK], [MASK] \\
        パディング方向 & 右側（post） \\
        切り詰め方向 & 右側（post） \\
        \bottomrule
    \end{tabular}
    }
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{教師データ}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{ラベリング手順}
感情分類モデルの構築のため，全83,851件の自由記述からランダムに1,000件を抽出し，手動でラベリングを行った．ラベルはネガティブ（−1），ニュートラル（0），ポジティブ（+1）の3クラスとした．

ラベリングは以下の基準に従って実施した．

\begin{itemize}
\item \textbf{ポジティブ}: 授業に対する肯定的評価，満足感，感謝の表明を含む記述
\item \textbf{ネガティブ}: 授業に対する否定的評価，不満，改善要望を含む記述
\item \textbf{ニュートラル}: 事実の記述，中立的な感想，感情を含まない記述
\end{itemize}

\subsection{ラベル分布}
教師データのラベル分布を表\ref{tab:labeldist-method}に示す．ニュートラルが全体の62.8\%を占める一方，ネガティブ（19.1\%）とポジティブ（18.0\%）は少数である．このクラス不均衡は，多くの学生が中立的な記述を行う傾向を反映していると考えられる．

\begin{table}[t]
    \centering
    \caption{教師データのラベル分布（1,000件）}
    \label{tab:labeldist-method}
    \resizebox{0.6\textwidth}{!}{
    \begin{tabular}{l r r}
        \toprule
        ラベル & 件数 & 割合 \\
        \midrule
        ネガティブ & 191 & 19.1\% \\
        ニュートラル & 628 & 62.8\% \\
        ポジティブ & 180 & 18.0\% \\
        \midrule
        合計 & 1,000 & 100.0\% \\
        \bottomrule
    \end{tabular}
    }
\end{table}

\subsection{各クラスの語彙的特徴}
各感情クラスの語彙的特徴を視覚的に把握するため，クラスごとのワードクラウドを作成した．図\ref{fig:wordcloud}に，ポジティブ，ニュートラル，ネガティブの各クラスにおける出現頻度の高い語彙を示す．

\begin{figure}[t]
    \centering
    \begin{minipage}{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{fig/POSITIVE_min3_wordcloud.png}
        \subcaption{ポジティブ}
    \end{minipage}
    \hfill
    \begin{minipage}{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{fig/NEUTRAL_min3_wordcloud.png}
        \subcaption{ニュートラル}
    \end{minipage}
    \hfill
    \begin{minipage}{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{fig/NEGATIVE_min3_wordcloud.png}
        \subcaption{ネガティブ}
    \end{minipage}
    \caption{各感情クラスの語彙的特徴（ワードクラウド）}
    \label{fig:wordcloud}
\end{figure}

ポジティブクラスでは，「継続」「努める」「心掛ける」「目指す」「健康」など，前向きな行動意欲や成長志向を示す語彙が頻出している．これらは学生の学習意欲や授業への積極的な姿勢を反映していると考えられる．

ニュートラルクラスでは，「統一」「許可」「質疑」「本学」「接続」など，事実の報告や要望を示す語彙が多い．感情的な色彩が薄く，授業内容や運営に関する客観的な記述が中心となっている．

ネガティブクラスでは，「早口」「悲しい」「腹立たい」「可笑しい」など，不満や困惑を示す語彙が確認できる．特に授業の進行速度や説明の明確さに関する不満が表れている．

このように，各クラスは語彙的に明確な特徴を持っており，感情分類モデルがこれらの語彙パターンを学習することで，自由記述の感情極性を判定できると期待される．

\subsection{データ分割}
教師データは訓練用と検証用に分割した．訓練データは800件（80\%），検証データは200件（20\%）とし，層化抽出によりラベル分布を維持した．

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{BERTモデルの概要}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{BERTのアーキテクチャ}
BERT（Bidirectional Encoder Representations from Transformers）は，Transformerのエンコーダ部分を用いた事前学習済み言語モデルである\cite{bert}．BERTの特徴は，双方向の文脈情報を同時に考慮できる点にある．

BERTの基本構成を表\ref{tab:bert_arch}に示す．本研究では，日本語に対応した事前学習済みモデルを使用した．

\begin{table}[t]
    \centering
    \caption{BERTモデルの基本構成}
    \label{tab:bert_arch}
    \resizebox{0.7\textwidth}{!}{
    \begin{tabular}{l r}
        \toprule
        項目 & 値 \\
        \midrule
        エンコーダ層数 & 12 \\
        隠れ層次元数 & 768 \\
        アテンションヘッド数 & 12 \\
        パラメータ数 & 約1.1億 \\
        最大入力トークン数 & 512 \\
        \bottomrule
    \end{tabular}
    }
\end{table}

\subsection{事前学習済みモデル}
本研究では，日本語の大規模コーパスで事前学習されたBERTモデルを使用した．具体的には，東北大学が公開している「cl-tohoku/bert-base-japanese-whole-word-masking」を基盤とし，感情分析タスクで微調整されたモデル（koheiduck/bert-japanese-finetuned-sentiment）を使用した．

事前学習では，Masked Language Model（MLM）タスクとNext Sentence Prediction（NSP）タスクにより，日本語の言語構造と文脈理解を学習している．この事前学習により，少量の教師データでも効果的な微調整が可能となる．

\subsection{Transformerの仕組み}
BERTの基盤となるTransformerは，Self-Attention機構により入力系列の全要素間の関係を並列に計算する\cite{transformer}．Self-Attentionは以下の式で表される．

\begin{equation}
\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V
\label{eq:attention}
\end{equation}

ここで，$Q$はクエリ，$K$はキー，$V$はバリューであり，$d_k$はキーの次元数である．この機構により，文中の離れた位置にある単語間の関係も効率的に捉えることができる．

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{モデル構成}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{感情分類モデル}
感情分類モデルは，BERTエンコーダに分類ヘッドを接続した構成である．BERTの出力のうち，[CLS]トークンに対応する768次元のベクトルを分類ヘッドへ入力し，3クラス（ネガティブ，ニュートラル，ポジティブ）の確率分布を出力する．

分類ヘッドは以下の構成である．

\begin{enumerate}
\item ドロップアウト層（$p=0.1$）
\item 全結合層（768次元 → 3次元）
\item ソフトマックス活性化関数
\end{enumerate}

損失関数にはクロスエントロピー損失を使用した．クラス不均衡に対処するため，各クラスの逆頻度に基づく重み付けを適用した．損失関数は以下の式で表される．

\begin{equation}
\mathcal{L}_{\text{sentiment}} = -\sum_{i=1}^{N} \sum_{c=1}^{3} w_c \cdot y_{i,c} \log(\hat{y}_{i,c})
\label{eq:ce_loss}
\end{equation}

ここで，$N$はサンプル数，$y_{i,c}$はサンプル$i$のクラス$c$の正解ラベル（one-hot），$\hat{y}_{i,c}$は予測確率，$w_c$はクラス$c$の重みである．

感情分類モデルのアーキテクチャを図\ref{fig:sentiment_model}に示す．

\begin{figure}[t]
\centering
\begin{tabular}{c}
\hline
\textbf{感情分類モデルの構成} \\
\hline
入力テキスト \\
$\downarrow$ \\
トークナイザ（WordPiece） \\
$\downarrow$ \\
BERTエンコーダ（12層，768次元） \\
$\downarrow$ \\
{[}CLS{]}トークンの出力ベクトル \\
$\downarrow$ \\
ドロップアウト（$p=0.1$） \\
$\downarrow$ \\
全結合層（768→3） \\
$\downarrow$ \\
ソフトマックス \\
$\downarrow$ \\
3クラス確率（ネガ/ニュートラル/ポジ） \\
\hline
\end{tabular}
\caption{感情分類モデルのアーキテクチャ}
\label{fig:sentiment_model}
\end{figure}

\subsection{マルチタスク学習モデル}
マルチタスク学習では，感情スコア予測と授業評価スコア予測を同時に学習するモデルを構築した\cite{mtl}．BERTエンコーダを共有表現として使用し，感情分類ヘッドと評価スコア予測ヘッドを分岐させる構成とした．

この構成の利点は以下の通りである．

\begin{enumerate}
\item \textbf{共有表現の学習}: 両タスクに共通する特徴（満足度要因）を効率的に学習できる
\item \textbf{正則化効果}: 複数タスクの同時学習により過学習を抑制できる
\item \textbf{要因分離}: SHAP分析と組み合わせることで，共通要因と特化要因を分離できる
\end{enumerate}

マルチタスクモデルの損失関数は，感情分類損失と評価スコア予測損失の重み付き和として定義される．

\begin{equation}
\mathcal{L}_{\text{total}} = \alpha \cdot \mathcal{L}_{\text{sentiment}} + \beta \cdot \mathcal{L}_{\text{score}}
\label{eq:mtl_loss}
\end{equation}

ここで，$\alpha$と$\beta$は各タスクの重みである．本研究では，$\alpha = 0.5$，$\beta = 0.5$として均等な重み付けを採用した．

評価スコア予測の損失関数には平均二乗誤差（MSE）を使用した．

\begin{equation}
\mathcal{L}_{\text{score}} = \frac{1}{N}\sum_{i=1}^{N} (y_i - \hat{y}_i)^2
\label{eq:mse_loss}
\end{equation}

マルチタスク学習モデルのアーキテクチャを図\ref{fig:mtl_model}に示す．

\begin{figure}[t]
\centering
\begin{tabular}{c}
\hline
\textbf{マルチタスク学習モデルの構成} \\
\hline
入力テキスト \\
$\downarrow$ \\
BERTエンコーダ（共有） \\
$\downarrow$ \\
{[}CLS{]}トークンの出力ベクトル（768次元） \\
$\swarrow$ \hspace{2cm} $\searrow$ \\
感情分類ヘッド \hspace{1cm} 評価スコア予測ヘッド \\
$\downarrow$ \hspace{2.5cm} $\downarrow$ \\
3クラス確率 \hspace{1.5cm} 評価スコア（回帰値） \\
\hline
\end{tabular}
\caption{マルチタスク学習モデルのアーキテクチャ}
\label{fig:mtl_model}
\end{figure}

\subsection{順序回帰モデル}
授業評価スコアは1点から4点までの順序尺度であり，単純な回帰や分類では順序関係を適切に扱えない．本研究では，順序回帰モデルを構築し，評価段階の順序性を考慮した予測を行う\cite{coral}．

順序回帰では，各閾値を超える確率を推定する．評価スコアが$k$以上となる確率$P(Y \geq k)$を累積確率として推定し，隣接する累積確率の差から各評価段階の確率を算出する．

\begin{equation}
P(Y = k) = P(Y \geq k) - P(Y \geq k+1)
\label{eq:ordinal}
\end{equation}

順序回帰モデルの詳細な結果は，追加実験の完了後に第4章で報告する．

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{学習設定}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{ハイパーパラメータ}
モデル学習のハイパーパラメータを表\ref{tab:hyperparams}に示す．これらのパラメータは予備実験により調整した．

\begin{table}[t]
    \centering
    \caption{学習のハイパーパラメータ}
    \label{tab:hyperparams}
    \resizebox{0.75\textwidth}{!}{
    \begin{tabular}{l r l}
        \toprule
        パラメータ & 値 & 選定理由 \\
        \midrule
        バッチサイズ & 16 & GPUメモリ制約を考慮 \\
        学習率 & $5 \times 10^{-6}$ & 事前学習済みモデルの微調整に適した低学習率 \\
        エポック数 & 5 & 早期終了により過学習を防止 \\
        最大トークン長 & 512 & BERTの最大入力長 \\
        ドロップアウト率 & 0.1 & 過学習抑制のための標準的な値 \\
        ウォームアップステップ & 100 & 学習初期の安定化 \\
        \bottomrule
    \end{tabular}
    }
\end{table}

\subsection{最適化手法}
最適化にはAdamWオプティマイザを使用した\cite{bert}．AdamWは，重み減衰を正則化として分離することで，Adamの欠点を改善した手法である．学習率スケジューラには線形減衰を採用し，ウォームアップ期間の後に学習率を線形に減少させた．

\subsection{早期終了}
過学習を防ぐため，検証損失が3エポック連続で改善しない場合に学習を終了する早期終了を適用した．最終的なモデルは，検証損失が最小となったエポックのパラメータを採用した．

\subsection{データ分割}
教師データ1,000件を以下のように分割した．

\begin{itemize}
\item 訓練データ: 800件（80\%）
\item 検証データ: 200件（20\%）
\end{itemize}

分割は層化抽出により行い，各セットでラベル分布が維持されるようにした．

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{授業単位集約と相関分析}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{授業単位の集約}
感情分類モデルにより全83,851件の自由記述に対して感情スコアを推定した後，授業単位で感情スコアを集約した．各授業の感情スコアは，その授業に属する自由記述の感情スコアの算術平均として算出した．

\begin{equation}
\bar{S}_j = \frac{1}{n_j}\sum_{i=1}^{n_j} s_{ij}
\label{eq:agg}
\end{equation}

ここで，$\bar{S}_j$は授業$j$の感情スコア平均，$n_j$は授業$j$の自由記述数，$s_{ij}$は授業$j$の$i$番目の自由記述の感情スコアである．

\subsection{相関分析手法}
授業単位の感情スコアと授業評価スコアの関係性を検討するため，以下の3種類の相関係数を算出した．

\begin{enumerate}
\item \textbf{ピアソン相関係数}: 線形関係の強さを測定
\item \textbf{スピアマン順位相関係数}: 順位に基づく単調関係を測定
\item \textbf{ケンドール順位相関係数}: 順位の一致度を測定
\end{enumerate}

相関分析にはSciPyライブラリを使用し，有意確率（$p$値）を併記して統計的有意性を確認した．

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{SHAP分析}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{SHAPの概要}
SHAP（SHapley Additive exPlanations）は，協力ゲーム理論のShapley値に基づく特徴量重要度の算出手法である\cite{shap}．SHAPは，各特徴量がモデル予測にどの程度寄与しているかを定量化できる．

SHAP値$\phi_i$は以下の式で定義される．

\begin{equation}
\phi_i = \sum_{S \subseteq N \setminus \{i\}} \frac{|S|!(|N|-|S|-1)!}{|N|!} [f(S \cup \{i\}) - f(S)]
\label{eq:shap}
\end{equation}

ここで，$N$は全特徴量の集合，$S$は$i$を含まない部分集合，$f(S)$は特徴量集合$S$を用いた予測値である．

\subsection{分析対象とサンプリング}
SHAP分析は計算コストが高いため，層化サンプリングにより5,000件のサンプルを抽出して分析を行った．また，出現回数が5回未満の低頻度語はノイズとなる可能性があるため除外し，最終的に1,564語を分析対象とした．

分析対象の設定を表\ref{tab:shap_setting}に示す．

\begin{table}[t]
    \centering
    \caption{SHAP分析の設定}
    \label{tab:shap_setting}
    \resizebox{0.7\textwidth}{!}{
    \begin{tabular}{l r}
        \toprule
        項目 & 値 \\
        \midrule
        分析サンプル数 & 5,000件 \\
        サンプリング手法 & 層化サンプリング \\
        最小出現回数閾値 & 5回 \\
        分析対象語彙数 & 1,564語 \\
        \bottomrule
    \end{tabular}
    }
\end{table}

\subsection{要因分類の閾値}
マルチタスクモデルのSHAP分析では，感情スコアと評価スコアへの寄与度に基づき，語彙を4つの要因グループに分類した．分類の閾値は重要度0.0005とした．

\begin{itemize}
\item \textbf{共通要因}: 感情重要度 $\geq$ 0.0005 かつ 評価重要度 $\geq$ 0.0005
\item \textbf{感情特化要因}: 感情重要度 $\geq$ 0.0005 かつ 評価重要度 $<$ 0.0005
\item \textbf{評価特化要因}: 感情重要度 $<$ 0.0005 かつ 評価重要度 $\geq$ 0.0005
\item \textbf{低重要度要因}: 感情重要度 $<$ 0.0005 かつ 評価重要度 $<$ 0.0005
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{評価指標}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{感情分類の評価指標}
感情分類モデルの性能評価には以下の指標を使用した．

\textbf{正解率（Accuracy）}は，全サンプルのうち正しく分類された割合である．

\begin{equation}
\text{Accuracy} = \frac{\text{正解数}}{\text{全サンプル数}}
\label{eq:accuracy}
\end{equation}

\textbf{適合率（Precision）}は，あるクラスと予測したサンプルのうち，実際にそのクラスであった割合である．

\begin{equation}
\text{Precision}_c = \frac{TP_c}{TP_c + FP_c}
\label{eq:precision}
\end{equation}

\textbf{再現率（Recall）}は，実際にあるクラスであるサンプルのうち，そのクラスと正しく予測された割合である．

\begin{equation}
\text{Recall}_c = \frac{TP_c}{TP_c + FN_c}
\label{eq:recall}
\end{equation}

\textbf{F1スコア}は，適合率と再現率の調和平均である．

\begin{equation}
\text{F1}_c = \frac{2 \cdot \text{Precision}_c \cdot \text{Recall}_c}{\text{Precision}_c + \text{Recall}_c}
\label{eq:f1}
\end{equation}

クラス間の不均衡を考慮するため，マクロ平均F1スコアと重み付き平均F1スコアの両方を報告する．

\subsection{回帰の評価指標}
授業評価スコア予測の性能評価には以下の指標を使用した．

\textbf{決定係数（$R^2$）}は，予測値が実測値の分散をどの程度説明できるかを示す．

\begin{equation}
R^2 = 1 - \frac{\sum_{i=1}^{N}(y_i - \hat{y}_i)^2}{\sum_{i=1}^{N}(y_i - \bar{y})^2}
\label{eq:r2}
\end{equation}

\textbf{平均二乗誤差（RMSE）}は，予測誤差の大きさを示す．

\begin{equation}
\text{RMSE} = \sqrt{\frac{1}{N}\sum_{i=1}^{N}(y_i - \hat{y}_i)^2}
\label{eq:rmse}
\end{equation}

\textbf{平均絶対誤差（MAE）}は，予測誤差の絶対値の平均である．

\begin{equation}
\text{MAE} = \frac{1}{N}\sum_{i=1}^{N}|y_i - \hat{y}_i|
\label{eq:mae}
\end{equation}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{分析フロー}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

本研究の分析フローを図\ref{fig:flow}に示す．

\begin{figure}[t]
\centering
\begin{tabular}{|l|}
\hline
\textbf{【データ収集】} \\
授業評価アンケート（3,268授業，83,851件自由記述） \\
\hline
$\downarrow$ \\
\hline
\textbf{【前処理】} \\
テキスト正規化，トークナイザによる分割 \\
\hline
$\downarrow$ \\
\hline
\textbf{【教師データ作成】} \\
1,000件の手動ラベリング（3クラス） \\
\hline
$\downarrow$ \\
\hline
\textbf{【モデル構築】} \\
感情分類モデル（BERT + 分類ヘッド） \\
マルチタスク学習モデル（BERT + 2ヘッド） \\
\hline
$\downarrow$ \\
\hline
\textbf{【感情スコア推定】} \\
全自由記述に対する感情スコア推定 \\
\hline
$\downarrow$ \\
\hline
\textbf{【授業単位集約】} \\
授業ごとの感情スコア平均を算出 \\
\hline
$\downarrow$ \\
\hline
\textbf{【相関分析】} \\
感情スコアと授業評価スコアの相関を検証 \\
\hline
$\downarrow$ \\
\hline
\textbf{【SHAP分析】} \\
5,000件サンプル，1,564語を対象に要因分析 \\
要因を4グループに分類 \\
\hline
\end{tabular}
\caption{分析フローの概略}
\label{fig:flow}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{実装環境}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

本研究の実装環境を表\ref{tab:env}に示す．

\begin{table}[t]
    \centering
    \caption{実装環境}
    \label{tab:env}
    \resizebox{0.7\textwidth}{!}{
    \begin{tabular}{l l}
        \toprule
        項目 & 内容 \\
        \midrule
        プログラミング言語 & Python 3.10 \\
        深層学習フレームワーク & PyTorch 2.0 \\
        Transformersライブラリ & Hugging Face Transformers 4.30 \\
        SHAP分析ライブラリ & SHAP 0.42 \\
        統計分析ライブラリ & SciPy 1.11 \\
        \bottomrule
    \end{tabular}
    }
\end{table}

本章では，データセットの概要，前処理手順，BERTを基盤とした感情分類モデルおよびマルチタスク学習モデルの構成，学習設定，SHAP分析の手法，および評価指標について詳述した．次章では，これらの手法を用いて得られた結果を報告する．
