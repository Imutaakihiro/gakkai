---
alwaysApply: true
---

# 卒業研究の流れ

## フェーズ1: データセット準備 ✅
- [x] データセットを作成する
- [x] 評価スコアのモデル作成方法を確立

## フェーズ2: 3つのモデル構築 ✅
**重要**: すべてのモデルは`koheiduck/bert-japanese-finetuned-sentiment`をベースとする

### 2.1 単一タスクモデル1: 自由記述→感情スコア
- [x] モデル構築（既存モデル使用）
- [x] 訓練実行（完了済み）
- [x] 性能評価（Accuracy, F1-Score, Precision, Recall）- `evaluate_sentiment_model.py`
- [x] モデル保存（完了済み）

### 2.2 単一タスクモデル2: 自由記述→評価スコア
- [x] モデル構築（`train_score_model.py`）
- [x] 訓練実行
- [x] 性能評価（RMSE, MAE, R², 相関係数）
- [x] モデル保存

### 2.3 マルチタスクモデル: 自由記述→感情スコア+評価スコア
- [x] モデル構築（`train_multitask_model.py`）
- [x] 訓練実行
- [x] 性能評価（両タスクの指標）
- [x] モデル保存

## フェーズ3: モデル性能比較 ✅
- [x] 3つのモデルの性能を定量的に比較（`compare_models.py`）
  - [x] 感情分析性能（Accuracy, F1, Precision, Recall）
  - [x] 評価スコア予測性能（RMSE, MAE, R², 相関係数）
- [x] 比較結果の可視化（グラフ作成）
- [x] 考察: マルチタスク学習のメリット・デメリット
  - メリット: 2つのタスクを同時に学習
  - デメリット: 単一タスクより精度が下がる可能性

## フェーズ4: SHAP分析実装 🔍
- [ ] 文章単位のSHAP分析を実装
- [ ] 各モデルでSHAP値を計算
- [ ] 単語・トークンの重要度を可視化
- [ ] モデル間の解釈可能性を比較

## フェーズ5: 結果分析 📈
- [ ] SHAP分析結果の定量的分析
- [ ] 目視で確認
  - [ ] 重要な単語・フレーズの特定
  - [ ] モデルの判断根拠を確認
  - [ ] 予測ミスのパターン分析
- [ ] 具体例の抽出（良い予測・悪い予測）

## フェーズ6: 結果まとめ 📝
- [ ] 実験結果の整理
- [ ] 表・グラフの作成
- [ ] 発見事項のリスト化
- [ ] 考察の執筆

## フェーズ7: 卒論執筆 📚
- [ ] 卒論の構成を考える
  - [ ] 序論（研究背景・目的）
  - [ ] 関連研究
  - [ ] 提案手法
  - [ ] 実験設定
  - [ ] 実験結果
  - [ ] 考察
  - [ ] 結論
- [ ] 各章の執筆
- [ ] 図表の作成・配置
- [ ] 査読・修正

## フェーズ8: プレゼン準備 🎤
- [ ] プレゼン資料を作成する
- [ ] 発表原稿の作成
- [ ] リハーサル
- [ ] 質疑応答の準備

---

## 注意事項
- 全てのモデルは同じベースモデル（`koheiduck/bert-japanese-finetuned-sentiment`）を使用
- 比較の公平性を保つため、データセット・評価指標を統一
- 実験結果は適切に保存・管理
