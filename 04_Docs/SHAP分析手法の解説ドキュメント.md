# SHAP分析手法の解説ドキュメント

## 📊 SHAPとは

**SHAP (SHapley Additive exPlanations)** は、機械学習モデルを解釈するための有用な手法です。

### 🎯 SHAPの特徴

- **定量的な寄与度算出**: モデルの予測に対し、特徴量（説明変数）の寄与度を定量的に算出
- **アルゴリズム非依存**: モデルのアルゴリズムの種類（決定木・線形回帰など）に限定されない
- **汎用性**: 様々な場面で使用可能
- **人気の高さ**: モデル解釈の分野で広く採用されている

## 🔧 SHAP値の算出方法

### 📋 基本的な手順

1. **モデルの準備**: 訓練済みの機械学習モデルを用意
2. **Explainerの作成**: `shap.Explainer()`にモデルを渡す
3. **SHAP値の算出**: 説明変数（特徴量）を渡してSHAP値を計算

### 💻 実装例

```python
import shap
import xgboost

# 1. モデルの訓練
model = xgboost.XGBRegressor()
model.fit(X, y)

# 2. SHAP値の算出
explainer = shap.Explainer(model)
shap_values = explainer(X)
```

## 📈 SHAPの主要な可視化手法

### 1. 🌊 Waterfallプロット

**用途**: 各データごとの予測に対する説明変数の寄与度を確認

**特徴**:
- 各データごとに確認可能
- 教師データから大きく外れた予測の原因調査に有効
- 基準値からの寄与度を視覚的に表示

**実装**:
```python
shap.plots.waterfall(shap_values[0])  # 1番目のデータを描画
```

**グラフの見方**:
- `E[f(x)]`: 訓練データに対するモデルの予測結果の平均値（基準値）
- `f(x)`: 実際の予測結果
- **赤色**: 正値への寄与
- **青色**: 負値への寄与

### 2. 🐝 Beeswarmプロット

**用途**: 全体的な特徴量の重要度と分布を把握

**特徴**:
- 全データのSHAP値の分布を一覧表示
- 特徴量の重要度を横軸の位置で表現
- 各特徴量のSHAP値の分布を縦軸で表現

**実装**:
```python
shap.plots.beeswarm(shap_values)
```

### 3. 📊 Scatterプロット

**用途**: 特徴量間の交互作用の可能性を推定

**特徴**:
- 横軸: 1つの説明変数
- 縦軸: SHAP値
- 交互作用の存在可能性を推定可能

**交互作用の判定**:
- 横軸固定で縦軸（SHAP値）に分布の広がりがある場合
- 他の説明変数の影響を示唆
- 線形関係でないことを意味

## 🎯 SHAPの活用場面

### 📚 教育・研究分野での応用

**本研究での活用**:
- **感情分析**: 自由記述から感情スコア予測の要因分析
- **評価予測**: 授業評価スコア予測の要因分析
- **マルチタスク学習**: 複数タスク間の要因の違いを分析

### 🔍 具体的な分析内容

**1. 要因の分類**:
- **共通要因**: 感情スコアと評価スコアの両方に影響
- **感情特化要因**: 感情スコアのみに影響
- **評価特化要因**: 評価スコアのみに影響
- **低重要度要因**: 両方のスコアに影響が小さい

**2. 閾値による分類**:
```
if 感情重要度 >= 0.0005 AND 評価重要度 < 0.0005:
    カテゴリ = "感情特化"
elif 感情重要度 < 0.0005 AND 評価重要度 >= 0.0005:
    カテゴリ = "評価特化"
elif 感情重要度 >= 0.0005 AND 評価重要度 >= 0.0005:
    カテゴリ = "共通要因"
else:
    カテゴリ = "低重要度"
```

## 📊 SHAP分析の利点

### ✅ メリット

1. **解釈可能性**: モデルの予測根拠を定量的に説明
2. **汎用性**: 様々な機械学習アルゴリズムに適用可能
3. **視覚化**: 直感的なグラフで結果を理解
4. **個別分析**: 各データポイントごとの分析が可能
5. **交互作用検出**: 特徴量間の関係性を発見

### ⚠️ 注意点

1. **計算コスト**: 大量のデータでは計算時間が長くなる
2. **解釈の複雑さ**: 結果の解釈には専門知識が必要
3. **閾値設定**: 分類のための閾値設定が重要
4. **交互作用の判定**: 実際の交互作用の存在は別途検証が必要

## 🚀 実用的な活用方法

### 📈 教育改善への応用

**1. 共通要因の活用**:
- 1つの施策で感情と評価の両方を改善
- 効率的な教育改善戦略の立案

**2. 特化要因の活用**:
- 感情特化: 学生満足度の向上
- 評価特化: 教育効果の向上

**3. リアルタイム分析**:
- 自由記述から即座に要因を把握
- 授業改善の即時フィードバック

## 📚 参考文献

- [SHAP公式GitHub](https://github.com/slundberg/shap)
- [DATAFLUCT Tech Blog - SHAPで機械学習モデルを解釈してみた](https://tech.datafluct.com/entry/20220223/1645624741)

## 🎯 まとめ

SHAPは機械学習モデルの解釈において非常に有用な手法です。特に本研究では、マルチタスク学習における要因分析に活用し、教育改善のための実用的な洞察を得ることができました。

**主要な成果**:
- 感情と評価の予測要因を定量的に分析
- 共通要因と特化要因の分類
- 教育改善戦略の立案支援
- リアルタイム分析の可能性

---

*このドキュメントは、SHAP分析手法の基本的な理解と、本研究での具体的な活用方法をまとめたものです。*
