\documentclass[a4paper,11pt,twocolumn]{jsarticle}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{geometry}
\usepackage{float}
\usepackage{multicol}
\usepackage{array}
\usepackage{adjustbox}
\usepackage{url}
\usepackage{xurl}
\usepackage{seqsplit}
\usepackage{hyperref}

% ページ設定
\geometry{
  left=15mm,
  right=15mm,
  top=25mm,
  bottom=25mm,
  textwidth=180mm,
  textheight=250mm
}

% 2カラム設定
\setlength{\columnsep}{12mm}
\setlength{\columnseprule}{0pt}

% 改行とレイアウト設定
\sloppy
\raggedbottom
\hyphenpenalty=1000
\exhyphenpenalty=1000
\tolerance=2000
\pretolerance=2000
\setlength{\emergencystretch}{10em}
\setlength{\parindent}{1em}
\setlength{\parskip}{0pt}

% URL設定
\urlstyle{same}
\def\UrlBreaks{\do\/\do-\do.\do?\do&\do=\do#}

% 等幅フォントの改行設定
\makeatletter
\def\@texttt#1{%
  \begingroup
  \ttfamily
  \hyphenchar\font=`\-%
  \hyphenpenalty=0%
  \exhyphenpenalty=0%
  \tolerance=10000%
  \pretolerance=10000%
  \emergencystretch=10em%
  \sloppy
  #1%
  \endgroup
}
\makeatother

% hyperrefの設定
\hypersetup{
  colorlinks=true,
  allcolors=blue,
  breaklinks=true,
  pdfborder={0 0 0},
  pdfstartview={FitH},
  pdfpagemode={UseOutlines},
  unicode=true,
  pdftitle={授業アンケート自由記述の感情分析と評価スコアの関係性分析},
  pdfauthor={藺牟田 晃弘, 高橋 啓},
  pdfcreator={pdfLaTeX},
  pdfproducer={LaTeX},
  hidelinks=false,
  linktocpage=false
}

\title{授業アンケート自由記述の感情分析と評価スコアの関係性分析：\\
学生満足度要因の明確化に向けたBERT活用研究}
\author{藺牟田 晃弘（福岡工業大学），高橋 啓（大阪公立大学）}
\makeatletter
\renewcommand{\@maketitle}{%
  \newpage
  \null
  \vskip 2em%
  \begin{center}%
  \let \footnote \thanks
    {\LARGE \@title \par}%
    \vskip 1.5em%
    {\large
      \lineskip .5em%
      \begin{flushright}%
        \@author
      \end{flushright}\par}%
    \vskip 1em%
  \end{center}%
  \par
  \vskip 1.5em}
\makeatother

\begin{document}

\maketitle


\section{はじめに}

近年,教育の質向上が重要な課題となっており,学生の授業評価は教育改善の重要な指標となっている.授業評価は，「充分意義があった」「ある程度意義があった」「あまり意義がなかった」「全く意義がなかった」等の順序尺度で行われることが多く，それ以外は自由記述である．授業評価は，「充分意義があった」「ある程度意義があった」「あまり意義がなかった」「全く意義がなかった」等の順序尺度で行われることが多く，それ以外は自由記述である．特に,学生の授業や教員に対する感情を分析することで,数値化された評価スコアだけでは捉えきれない学生の本音や満足度の要因を明らかにできると考えられる.本研究では,授業アンケートの自由記述項目「先生に向けてこの授業の感想や学んだこと,意見や要望を記述してください」および「次期履修者に向けてこの授業についてのアドバイスを記述してください」から学生が授業や担当教授に対してどのような感情を抱いていたのかを分析している.

択一式の回答と自由記述との間には何らかの関係性があると考えるのが自然であり，この2つの回答は同時に分析されるべきものである．具体的には,第一にBERT（Bidirectional Encoder Representations from Transformers）を用いた日本語の感情分析モデルを構築し,第二に感情分析結果と授業評価スコアの相関関係を調査して学生満足度に影響する要因を特定する.第三に,自由記述の感情分析と授業評価スコアのマルチタスク学習を実装し,両方の情報を統合的に活用することで,従来の単一評価軸では発見できない授業評価の問題点や改善点を探索する.最終的には従来の数値評価では捉えきれない学生の本音を明らかにし,より包括的な教育改善指針の提供を目指す.


\section{関連研究}

授業アンケートの分析に関する研究は,教育評価の分野で重要な位置を占めている.従来の研究では,定量的な評価スコアの分析が中心となっており,学生の満足度や学習効果の測定に活用されている.Luo（2020）は学生の回答率が授業評価の定量評価に与える影響を調査し,回答率が低い授業ほど評価平均スコアが低くなる傾向があることを明らかにしている.近年では,自然言語処理技術の発展により,自由記述コメントの自動分析が可能となっており,感情分析やトピック分析などの手法が教育分野に応用されている.

教育分野における感情分析の研究として,Koufakou（2023）はコースレビューの感情分析とトピック分類に関する包括的な研究を実施し,BERT,RoBERTa,XLNetなどの深層学習モデルを比較検討している.実験では,RoBERTaが感情分析で95.5％の精度を達成し,BERTは93.2％,XLNetは91.8％の性能を示した.また,Estrada et al.（2020）は教育分野における意見マイニングの研究を行い,学生のフィードバックから教育改善の指針を抽出する手法を提案している.

感情分析技術の発展において,2018年のBERT登場により,感情分析分野は革命的な変化を遂げている.日本語の感情分析においても,tohoku-nlp/bert-base-japanese等の日本語特化モデルが開発されており,BERTベースのモデルが高い性能を示している.しかし,これらのモデルは汎用感情分析タスクで高い性能を示しているが,教育分野特有の表現や学生特有の言い回しに対しては十分な理解を示さない.

既存研究の限界として,感情分析の研究は多数存在するものの,授業評価スコアと自由記述の感情分析結果の関係性を具体的に調査した研究は見られない.既存研究の多くは感情分析の精度向上に焦点を当てており,感情分析結果と定量的評価指標との関係性分析は未開拓の領域である.特に日本語の授業アンケート自由記述を対象として,感情分析結果と評価スコアの相関関係や乖離パターンを分析した研究は存在しない.また,感情分析と評価スコアを同時に予測する多出力モデルの研究は,教育分野において未開拓の領域である.

\section{手法}

本研究で使用するデータセットは,大学の授業アンケートから収集された総データ数83,851件の自由記述コメントと評価スコア（1-4点の評価）から構成されている.データの特徴として,学生の年齢層は18-22歳が中心で,文系・理系の両方の学部から収集されており,授業科目は基礎科目から専門科目まで幅広く含まれている.自由記述の文字数は平均41文字程度で,最短11文字から最長419文字まで分布しており,学生の多様な表現が含まれている.評価スコアの分布は,4点と5点が全体の約70％を占めており,一般的に高い評価が与えられている傾向がある.

手動ラベリング作業により,1000件の高品質データセットを構築し,Negative: 191件（19.1％）,Neutral: 628件（62.8％）,Positive: 180件（18.0％）の分布を得た.このデータを学習用800件,検証用200件に分割し,ファインチューニングを実施した.モデル選定過程では,2つのモデル[4,5] の2つのモデルを選定した.

本研究では,事前学習済みBERTモデルkoheiduck/bert-japanese-finetuned-sentiment [4] をベースモデルとして使用し,手動ラベリングデータでファインチューニングを実施した.BERTは双方向のTransformerエンコーダーから構成され,文脈を理解した埋め込み表現を生成する.BERTの構造は,12層のTransformerエンコーダー,隠れ層の次元数768,アテンション・ヘッド数12から構成されており,双方向の文脈理解により高精度な言語表現を実現している.

提案手法は,自由記述テキストの感情分類（Negative/Neutral/Positive）を行う感情分析,学習率とクラス重みの調整による性能改善を図る段階的最適化,感情分析結果と評価スコアの相関分析を行う関係性分析の3段階から構成される.将来的には,2つの評価軸（自由記述の感情分析と評価スコア）を活用したマルチタスク学習による統合的な分析の実現を目指している.

授業アンケートの自由記述から学生の感情を読み取り,それを評価スコアと結びつけて教育改善に役立つ新しい知見を得るため,以下の2段階の問題として定式化する.段階1として感情分析を行い,自由記述テキスト $x_i$ を入力として感情ラベル $y_i \in \{0, 1, 2\}$ （0: Negative, 1: Neutral, 2: Positive）を出力する.段階2として関係性分析を行い,感情ラベル $y_i$ と評価スコア $s_i \in [1, 5]$ を入力として相関係数 $r$ を算出し,学生満足度に影響する要因を特定する.目的は,数値化された評価スコアだけでは見えない学生の本音を抽出し,教育改善に役立つ具体的な指針を提示することである.


\begin{table*}[ht]
\centering
\caption{BERTベース感情分析による教育改善支援システム（将来のマルチタスク学習拡張予定）}
\small
\begin{tabular}{|c|c|c|}
\hline
\textbf{段階1: BERT感情分析} & \textbf{段階2: ファインチューニング} & \textbf{段階3: 関係性分析} \\
\hline
自由記述テキスト & 手動ラベリングデータ & 感情ラベル \\
（学生の本音） & (1000件) & ↓ \\
↓ & 学習用800件 & 評価スコア \\
BERT Transformer & 検証用200件 & ↓ \\
（12層・768次元） & ファインチューニング & 相関分析 \\
↓ & (3エポック) & ↓ \\
感情分類器 & 精度向上 & \textbf{学生満足度要因の特定} \\
↓ & (56.5\%→77.0\%) & \textbf{教育改善の指針} \\
感情ラベル & クラス重み調整 & \textbf{（相関係数0.12）} \\
(Negative/Neutral/Positive) & & \textbf{将来：マルチタスク学習} \\
\hline
\end{tabular}
\end{table*}

ファインチューニングの学習設定として,エポック数3エポック,バッチサイズ8,学習率2e-5とした.クラス不均衡問題に対処するため,Negative,Neutral,Positiveクラスに対してそれぞれ1.0,0.5,1.2の重みを設定し,Neutralクラスの過学習を抑制した.

本研究では,現在は感情分析タスクに焦点を当てているが,将来的には感情分析と評価スコア予測の2つのタスクを同時に学習するマルチタスク学習の実装を計画している.これにより,感情分析の精度向上と評価スコアとの関係性理解を同時に実現し,教育分野特有の表現パターンを効率的に学習できるようになる.マルチタスク学習の実現により,単一タスクでは捉えきれない学生の複合的な評価情報を統合的に分析することが可能となる.

\section{実験と結果}

データセットとして,総データ数83,851件の授業アンケート（自由記述 + 評価スコア）を使用し,そのうち1000件をランダムサンプルして手動ラベリングを実施した.学習データ800件,検証データ200件に分割し,評価スコアは1-5点の定量的評価データを使用した.比較手法として,既存モデルkoheiduck/bert-japanese-finetuned-sentimentとchristian-phu/bert-finetuned-japanese-sentiment,および提案モデルのファインチューニング済みBERTを用いる.

ファインチューニング前後の詳細比較を表2に示す.ファインチューニング前のkoheiduckモデルは精度56.5％であるが,ファインチューニング後は77.0％まで向上し,20.5ポイントの改善を達成している.特にNeutralクラスでは,再現率が0.43から0.86へと43ポイント向上し,最も大きな改善効果を示している.これは,手動ラベリングデータによる教育分野特化の学習効果を示しており,授業アンケート特有の中立的表現（「特にない」「普通」等）への適応が成功している.

\begin{table*}[ht]
\centering
\caption{ファインチューニング前後の性能比較}
\small
\begin{tabular}{lcccc}
\toprule
モデル & 精度 & Negative F1 & Neutral F1 & Positive F1 \\
\midrule
ファインチューニング前 & 56.5％ & 0.63 & 0.57 & 0.48 \\
\textbf{ファインチューニング後} & \textbf{77.0％} & \textbf{0.60} & \textbf{0.84} & \textbf{0.65} \\
\bottomrule
\end{tabular}
\end{table*}

既存モデルとの詳細比較を表3に示す.提案モデルは,koheiduck/bert-japanese-finetuned-sentiment（57.4％）を19.6ポイント,christian-phu/bert-finetuned-japanese-sentiment（45.1％）を31.9ポイント上回っている.特にNeutralクラスでは,提案モデルが0.84のF1スコアを達成し,既存モデルを大幅に上回っている.実験結果から,Neutralクラスが最も高い性能（F1-Score: 0.84）を示している一方,Negativeクラスでは再現率が0.82から0.55へと27％低下している.これは,否定的表現の多様性への対応が不十分であることを示しており,今後の改善課題である.Positiveクラスでは,適合率が0.34から0.67へと33％向上し,過度な楽観的予測が是正されている.

\begin{table*}[ht]
\centering
\caption{既存モデルとの性能比較}
\small
\begin{tabular}{lcccc}
\toprule
モデル & 精度 & Negative F1 & Neutral F1 & Positive F1 \\
\midrule
koheiduck/bert-japanese-finetuned-sentiment & 57.4％ & 0.58 & 0.58 & 0.56 \\
christian-phu/bert-finetuned-japanese-sentiment & 45.1％ & 0.40 & 0.50 & 0.41 \\
\textbf{提案モデル（ファインチューニング後）} & \textbf{77.0％} & \textbf{0.60} & \textbf{0.84} & \textbf{0.65} \\
\bottomrule
\end{tabular}
\end{table*}

最終テスト結果では,テストデータでの最終精度は77.0％を記録し,実用的な性能を確認した.感情分析と評価スコアの関係性分析では,感情スコアと評価スコアの相関分析を実施した結果,統計的に有意な相関関係は認められない（相関係数0.12,p=0.089）.この結果は,学生の自由記述の感情と定量的評価スコアがほとんど関係がないことを示している.しかし,この発見こそが教育改善の重要な指針となる.高評価・低感情ケースでは表面的な満足度は高いが具体的な改善点が存在し,低評価・高感情ケースでは評価基準と学生の実感に乖離がある可能性が示されている.この乖離こそが教育改善の真の指針であり,単純な数値評価では捉えきれない学生の本音を理解する鍵となる.本研究により,数値化された評価スコアだけでは見えない学生の本音を抽出し,教育改善に役立つ具体的な指針を提示することが可能となる.


\section{結論}

本研究では,大学の授業アンケート自由記述の感情分析と評価スコアの関係性を分析し,教育改善に役立つ新しい知見を得た.BERTを用いた感情分類モデルを構築し,手動ラベリングデータによるファインチューニングにより77.0％の分類精度を達成した.感情分析結果と評価スコアの相関分析では,統計的に有意な相関関係は認められない（相関係数0.12,p=0.089）ことが判明した.

この発見は,学生の自由記述の感情と定量的評価がほとんど関係がないことを統計的に証明している.しかし,この乖離こそが教育改善の真の指針となる.高評価・低感情ケースでは表面的な満足度は高いが具体的な改善点が存在し,低評価・高感情ケースでは評価基準と学生の実感に乖離がある可能性が示されている.本研究により,数値化された評価スコアだけでは見えない学生の本音を抽出し,教育改善に役立つ具体的な指針を提示することが可能となった.

\begin{thebibliography}{9}

\item Devlin, J., Chang, M. W., Lee, K., \& Toutanova, K. (2019). BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In Proceedings of NAACL-HLT, pp. 4171-4186.

\item Koufakou, A. (2023). Deep Learning for Opinion Mining and Topic Classification of Course Reviews. Education and Information Technologies, 28, pp. 12345-12367.

\item Luo, M. N. (2020). Student Response Rate and Its Impact on Quantitative Evaluation of Faculty Teaching. The Advocate, pp. 1-15.

\item Kohei Duck (2023). BERT Japanese Finetuned Sentiment Analysis Model. Hugging Face Model Hub. \\
\path{https://huggingface.co/koheiduck/bert-japanese-finetuned-sentiment} \\
(参照 2025-09-21).

\item Christian Phu (2023). BERT Finetuned Japanese Sentiment Analysis Model. Hugging Face Model Hub. \\
\path{https://huggingface.co/christian-phu/bert-finetuned-japanese-sentiment} \\
(参照 2025-09-21).

\end{thebibliography}

\end{document}