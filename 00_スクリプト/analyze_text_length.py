#!/usr/bin/env python3
"""
æˆæ¥­ã”ã¨ã®è‡ªç”±è¨˜è¿°ã®æ–‡å­—æ•°çµ±è¨ˆã‚’ç¢ºèªã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import pandas as pd
import numpy as np

def analyze_text_length():
    """è‡ªç”±è¨˜è¿°ã®æ–‡å­—æ•°çµ±è¨ˆã‚’åˆ†æ"""
    
    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿
    df = pd.read_csv('01_ãƒ‡ãƒ¼ã‚¿/ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯ç”¨ãƒ‡ãƒ¼ã‚¿/æˆæ¥­é›†ç´„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ_20251012_142504.csv')
    
    print("ğŸ“Š æˆæ¥­ã”ã¨ã®è‡ªç”±è¨˜è¿°æ–‡å­—æ•°çµ±è¨ˆ")
    print("=" * 50)
    
    # æ–‡å­—æ•°è¨ˆç®—
    text_lengths = df["è‡ªç”±è¨˜è¿°ã¾ã¨ã‚"].str.len()
    
    print(f"ğŸ“ˆ åŸºæœ¬çµ±è¨ˆ:")
    print(f"  å¹³å‡æ–‡å­—æ•°: {text_lengths.mean():.0f}æ–‡å­—")
    print(f"  ä¸­å¤®å€¤: {text_lengths.median():.0f}æ–‡å­—")
    print(f"  æœ€å°: {text_lengths.min()}æ–‡å­—")
    print(f"  æœ€å¤§: {text_lengths.max()}æ–‡å­—")
    print(f"  æ¨™æº–åå·®: {text_lengths.std():.0f}æ–‡å­—")
    
    print(f"\nğŸ“Š è©³ç´°åˆ†å¸ƒ:")
    print(text_lengths.describe())
    
    print(f"\nğŸ¯ ç¾åœ¨ã®MAX_LENGTHè¨­å®šã¨ã®æ¯”è¼ƒ:")
    print(f"  MAX_LENGTH = 128ãƒˆãƒ¼ã‚¯ãƒ³")
    print(f"  å¹³å‡æ–‡å­—æ•° = {text_lengths.mean():.0f}æ–‡å­—")
    print(f"  æ–‡å­—æ•°/ãƒˆãƒ¼ã‚¯ãƒ³æ¯” â‰ˆ 1.5-2.0 (æ—¥æœ¬èª)")
    print(f"  æ¨å®šãƒˆãƒ¼ã‚¯ãƒ³æ•° â‰ˆ {text_lengths.mean() * 1.75:.0f}ãƒˆãƒ¼ã‚¯ãƒ³")
    
    # 128ãƒˆãƒ¼ã‚¯ãƒ³ã§ã‚«ãƒãƒ¼ã§ãã‚‹å‰²åˆ
    estimated_tokens = text_lengths * 1.75
    coverage_128 = (estimated_tokens <= 128).mean() * 100
    coverage_256 = (estimated_tokens <= 256).mean() * 100
    coverage_512 = (estimated_tokens <= 512).mean() * 100
    
    print(f"\nğŸ“Š ãƒˆãƒ¼ã‚¯ãƒ³é•·ã§ã®ã‚«ãƒãƒ¼ç‡:")
    print(f"  128ãƒˆãƒ¼ã‚¯ãƒ³: {coverage_128:.1f}%ã®æˆæ¥­ã‚’ã‚«ãƒãƒ¼")
    print(f"  256ãƒˆãƒ¼ã‚¯ãƒ³: {coverage_256:.1f}%ã®æˆæ¥­ã‚’ã‚«ãƒãƒ¼")
    print(f"  512ãƒˆãƒ¼ã‚¯ãƒ³: {coverage_512:.1f}%ã®æˆæ¥­ã‚’ã‚«ãƒãƒ¼")
    
    # ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤º
    print(f"\nğŸ“ ã‚µãƒ³ãƒ—ãƒ«æˆæ¥­ï¼ˆæ–‡å­—æ•°é †ï¼‰:")
    sample_df = df.copy()
    sample_df['æ–‡å­—æ•°'] = sample_df["è‡ªç”±è¨˜è¿°ã¾ã¨ã‚"].str.len()
    sample_df = sample_df.sort_values('æ–‡å­—æ•°', ascending=False)
    
    for i, (_, row) in enumerate(sample_df.head(3).iterrows()):
        print(f"\n{i+1}. {row['æˆæ¥­ID']}")
        print(f"   æ–‡å­—æ•°: {row['æ–‡å­—æ•°']}æ–‡å­—")
        print(f"   è‡ªç”±è¨˜è¿°æ•°: {row['è‡ªç”±è¨˜è¿°æ•°']}ä»¶")
        print(f"   æ¨å®šãƒˆãƒ¼ã‚¯ãƒ³æ•°: {row['æ–‡å­—æ•°'] * 1.75:.0f}ãƒˆãƒ¼ã‚¯ãƒ³")
        print(f"   å†…å®¹ï¼ˆæœ€åˆã®100æ–‡å­—ï¼‰: {row['è‡ªç”±è¨˜è¿°ã¾ã¨ã‚'][:100]}...")

if __name__ == "__main__":
    analyze_text_length()
