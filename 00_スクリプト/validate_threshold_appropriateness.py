#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯å­¦ç¿’ã®é–¾å€¤è¨­å®šã®å¦¥å½“æ€§æ¤œè¨¼
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
import platform
if platform.system() == 'Windows':
    plt.rcParams['font.family'] = ['Yu Gothic', 'Meiryo', 'MS Gothic', 'MS Mincho', 'DejaVu Sans']
else:
    plt.rcParams['font.family'] = ['DejaVu Sans', 'Hiragino Sans', 'Yu Gothic', 'Meiryo', 'Takao']

plt.rcParams['axes.unicode_minus'] = False

def load_comparison_data():
    """æ¯”è¼ƒãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿"""
    print("ğŸ“Š æ¯”è¼ƒãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ä¸­...")
    
    # æ„Ÿæƒ…å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã®ãƒ‡ãƒ¼ã‚¿
    single_model_df = pd.read_csv('03_åˆ†æçµæœ/SHAPåˆ†æ/ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°5000ä»¶/word_importance_sample5000.csv')
    print(f"âœ… æ„Ÿæƒ…å˜ä¸€ãƒ¢ãƒ‡ãƒ«: {len(single_model_df)}èªå½™")
    
    # ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯ãƒ¢ãƒ‡ãƒ«ã®ãƒ‡ãƒ¼ã‚¿
    multitask_df = pd.read_csv('00_ã‚¹ã‚¯ãƒªãƒ—ãƒˆ/03_åˆ†æçµæœ/ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯SHAPåˆ†æ_æ–°é–¾å€¤0.0005/ãƒ‡ãƒ¼ã‚¿/æ–°é–¾å€¤åŒ…æ‹¬é‡è¦åº¦ãƒ‡ãƒ¼ã‚¿.csv')
    print(f"âœ… ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯ãƒ¢ãƒ‡ãƒ«: {len(multitask_df)}èªå½™")
    
    return single_model_df, multitask_df

def analyze_threshold_appropriateness(single_df, multitask_df):
    """é–¾å€¤è¨­å®šã®å¦¥å½“æ€§åˆ†æ"""
    print("\nğŸ” é–¾å€¤è¨­å®šã®å¦¥å½“æ€§åˆ†æä¸­...")
    
    # æ„Ÿæƒ…å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã®çµ±è¨ˆ
    single_stats = {
        'mean': single_df['mean_shap'].mean(),
        'std': single_df['mean_shap'].std(),
        'min': single_df['mean_shap'].min(),
        'max': single_df['mean_shap'].max(),
        'median': single_df['mean_shap'].median(),
        'q25': single_df['mean_shap'].quantile(0.25),
        'q75': single_df['mean_shap'].quantile(0.75)
    }
    
    # ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯ãƒ¢ãƒ‡ãƒ«ã®çµ±è¨ˆ
    multitask_stats = {
        'mean': multitask_df['total_importance'].mean(),
        'std': multitask_df['total_importance'].std(),
        'min': multitask_df['total_importance'].min(),
        'max': multitask_df['total_importance'].max(),
        'median': multitask_df['total_importance'].median(),
        'q25': multitask_df['total_importance'].quantile(0.25),
        'q75': multitask_df['total_importance'].quantile(0.75)
    }
    
    print("ğŸ“ˆ æ„Ÿæƒ…å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã®çµ±è¨ˆ:")
    for key, value in single_stats.items():
        print(f"  {key}: {value:.6f}")
    
    print("\nğŸ“ˆ ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯ãƒ¢ãƒ‡ãƒ«ã®çµ±è¨ˆ:")
    for key, value in multitask_stats.items():
        print(f"  {key}: {value:.6f}")
    
    # ã‚¹ã‚±ãƒ¼ãƒ«æ¯”ã®è¨ˆç®—
    scale_ratio = single_stats['mean'] / multitask_stats['mean']
    print(f"\nğŸ“Š ã‚¹ã‚±ãƒ¼ãƒ«æ¯”: {scale_ratio:.1f}å€")
    
    # é–¾å€¤ã®å¦¥å½“æ€§æ¤œè¨¼
    current_threshold = 0.0005
    equivalent_threshold = current_threshold * scale_ratio
    
    print(f"\nğŸ¯ é–¾å€¤ã®å¦¥å½“æ€§æ¤œè¨¼:")
    print(f"ç¾åœ¨ã®é–¾å€¤: {current_threshold}")
    print(f"æ„Ÿæƒ…å˜ä¸€ãƒ¢ãƒ‡ãƒ«ç›¸å½“: {equivalent_threshold:.4f}")
    print(f"æ„Ÿæƒ…å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã®æœ€å°å€¤: {single_stats['min']:.4f}")
    print(f"æ„Ÿæƒ…å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã®25%åˆ†ä½: {single_stats['q25']:.4f}")
    
    # æ¨å¥¨é–¾å€¤ã®è¨ˆç®—
    recommended_thresholds = {
        'conservative': multitask_stats['q25'],  # 25%åˆ†ä½
        'moderate': multitask_stats['median'],    # ä¸­å¤®å€¤
        'aggressive': multitask_stats['q75']      # 75%åˆ†ä½
    }
    
    print(f"\nğŸ’¡ æ¨å¥¨é–¾å€¤:")
    for level, threshold in recommended_thresholds.items():
        print(f"  {level}: {threshold:.6f}")
    
    return {
        'single_stats': single_stats,
        'multitask_stats': multitask_stats,
        'scale_ratio': scale_ratio,
        'current_threshold': current_threshold,
        'recommended_thresholds': recommended_thresholds
    }

def test_different_thresholds(multitask_df, analysis_results):
    """ç•°ãªã‚‹é–¾å€¤ã§ã®ãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ§ª ç•°ãªã‚‹é–¾å€¤ã§ã®ãƒ†ã‚¹ãƒˆä¸­...")
    
    thresholds_to_test = [
        0.0001,  # ç¾åœ¨ã®é–¾å€¤
        0.0005,  # æ–°ãŸãªé–¾å€¤
        analysis_results['recommended_thresholds']['conservative'],
        analysis_results['recommended_thresholds']['moderate'],
        analysis_results['recommended_thresholds']['aggressive']
    ]
    
    results = []
    
    for threshold in thresholds_to_test:
        # é–¾å€¤ä»¥ä¸Šã®é‡è¦åº¦ã‚’æŒã¤èªå½™ã‚’æŠ½å‡º
        high_importance = multitask_df[multitask_df['total_importance'] >= threshold]
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥çµ±è¨ˆ
        category_stats = high_importance['category'].value_counts()
        
        result = {
            'threshold': threshold,
            'total_words': len(high_importance),
            'common_words': category_stats.get('å…±é€šè¦å› ', 0),
            'sentiment_words': category_stats.get('æ„Ÿæƒ…ç‰¹åŒ–', 0),
            'course_words': category_stats.get('è©•ä¾¡ç‰¹åŒ–', 0),
            'low_words': category_stats.get('ä½é‡è¦åº¦', 0)
        }
        
        if result['total_words'] > 0:
            result['common_ratio'] = result['common_words'] / result['total_words'] * 100
        else:
            result['common_ratio'] = 0
        
        results.append(result)
        
        print(f"é–¾å€¤ {threshold:.6f}: ç·èªå½™æ•°={result['total_words']}, å…±é€šè¦å› ={result['common_words']} ({result['common_ratio']:.1f}%)")
    
    return results

def create_threshold_comparison_visualization(results, analysis_results):
    """é–¾å€¤æ¯”è¼ƒã®å¯è¦–åŒ–"""
    print("\nğŸ¨ é–¾å€¤æ¯”è¼ƒã®å¯è¦–åŒ–ä½œæˆä¸­...")
    
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
    fig.suptitle('ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯å­¦ç¿’ã®é–¾å€¤è¨­å®šå¦¥å½“æ€§æ¤œè¨¼', fontsize=16, fontweight='bold')
    
    thresholds = [r['threshold'] for r in results]
    total_words = [r['total_words'] for r in results]
    common_ratios = [r['common_ratio'] for r in results]
    
    # 1. ç·èªå½™æ•° vs é–¾å€¤
    ax1.plot(thresholds, total_words, 'o-', linewidth=2, markersize=8, color='#FF6B6B')
    ax1.set_xlabel('é–¾å€¤', fontsize=12)
    ax1.set_ylabel('ç·èªå½™æ•°', fontsize=12)
    ax1.set_title('é–¾å€¤ vs ç·èªå½™æ•°', fontsize=14, fontweight='bold')
    ax1.grid(True, alpha=0.3)
    ax1.set_xscale('log')
    
    # 2. å…±é€šè¦å› ã®å‰²åˆ vs é–¾å€¤
    ax2.plot(thresholds, common_ratios, 's-', linewidth=2, markersize=8, color='#4ECDC4')
    ax2.set_xlabel('é–¾å€¤', fontsize=12)
    ax2.set_ylabel('å…±é€šè¦å› ã®å‰²åˆ (%)', fontsize=12)
    ax2.set_title('é–¾å€¤ vs å…±é€šè¦å› ã®å‰²åˆ', fontsize=14, fontweight='bold')
    ax2.grid(True, alpha=0.3)
    ax2.set_xscale('log')
    
    # 3. ã‚«ãƒ†ã‚´ãƒªåˆ¥åˆ†å¸ƒï¼ˆç¾åœ¨ã®é–¾å€¤0.0005ï¼‰
    current_result = next(r for r in results if r['threshold'] == 0.0005)
    categories = ['å…±é€šè¦å› ', 'æ„Ÿæƒ…ç‰¹åŒ–', 'è©•ä¾¡ç‰¹åŒ–', 'ä½é‡è¦åº¦']
    counts = [current_result['common_words'], current_result['sentiment_words'], 
              current_result['course_words'], current_result['low_words']]
    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4']
    
    wedges, texts, autotexts = ax3.pie(counts, labels=categories, colors=colors, 
                                       autopct='%1.1f%%', startangle=90)
    ax3.set_title('ç¾åœ¨ã®é–¾å€¤(0.0005)ã§ã®åˆ†å¸ƒ', fontsize=14, fontweight='bold')
    
    # 4. æ¨å¥¨é–¾å€¤ã®æ¯”è¼ƒ
    recommended = analysis_results['recommended_thresholds']
    rec_labels = ['Conservative', 'Moderate', 'Aggressive']
    rec_values = [recommended['conservative'], recommended['moderate'], recommended['aggressive']]
    
    bars = ax4.bar(rec_labels, rec_values, color=['#FFB6C1', '#FF6B6B', '#DC143C'], alpha=0.8)
    ax4.set_ylabel('æ¨å¥¨é–¾å€¤', fontsize=12)
    ax4.set_title('æ¨å¥¨é–¾å€¤ã®æ¯”è¼ƒ', fontsize=14, fontweight='bold')
    
    # ç¾åœ¨ã®é–¾å€¤ã‚’ç·šã§è¡¨ç¤º
    ax4.axhline(y=0.0005, color='blue', linestyle='--', linewidth=2, label='ç¾åœ¨ã®é–¾å€¤(0.0005)')
    ax4.legend()
    
    plt.tight_layout()
    plt.savefig('00_ã‚¹ã‚¯ãƒªãƒ—ãƒˆ/03_åˆ†æçµæœ/ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯SHAPåˆ†æ_æ–°é–¾å€¤0.0005/é–¾å€¤å¦¥å½“æ€§æ¤œè¨¼.png', 
                dpi=300, bbox_inches='tight')
    plt.close()
    
    print("âœ… é–¾å€¤å¦¥å½“æ€§æ¤œè¨¼å¯è¦–åŒ–ä¿å­˜å®Œäº†")

def create_threshold_validation_report(results, analysis_results):
    """é–¾å€¤å¦¥å½“æ€§æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆã®ä½œæˆ"""
    print("\nğŸ“ é–¾å€¤å¦¥å½“æ€§æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆä½œæˆä¸­...")
    
    report = f"""# ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯å­¦ç¿’ã®é–¾å€¤è¨­å®šå¦¥å½“æ€§æ¤œè¨¼

## ğŸ¯ æ¤œè¨¼æ¦‚è¦
- æ¤œè¨¼æ—¥æ™‚: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}
- ç›®çš„: ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯å­¦ç¿’ã®é–¾å€¤0.0005ã®å¦¥å½“æ€§æ¤œè¨¼
- æ¯”è¼ƒå¯¾è±¡: æ„Ÿæƒ…å˜ä¸€ãƒ¢ãƒ‡ãƒ« vs ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯ãƒ¢ãƒ‡ãƒ«

## ğŸ“Š çµ±è¨ˆçš„æ¯”è¼ƒ

### æ„Ÿæƒ…å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã®çµ±è¨ˆ
| çµ±è¨ˆé‡ | å€¤ |
|--------|-----|
| å¹³å‡ | {analysis_results['single_stats']['mean']:.6f} |
| æ¨™æº–åå·® | {analysis_results['single_stats']['std']:.6f} |
| æœ€å°å€¤ | {analysis_results['single_stats']['min']:.6f} |
| æœ€å¤§å€¤ | {analysis_results['single_stats']['max']:.6f} |
| ä¸­å¤®å€¤ | {analysis_results['single_stats']['median']:.6f} |
| 25%åˆ†ä½ | {analysis_results['single_stats']['q25']:.6f} |
| 75%åˆ†ä½ | {analysis_results['single_stats']['q75']:.6f} |

### ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯ãƒ¢ãƒ‡ãƒ«ã®çµ±è¨ˆ
| çµ±è¨ˆé‡ | å€¤ |
|--------|-----|
| å¹³å‡ | {analysis_results['multitask_stats']['mean']:.6f} |
| æ¨™æº–åå·® | {analysis_results['multitask_stats']['std']:.6f} |
| æœ€å°å€¤ | {analysis_results['multitask_stats']['min']:.6f} |
| æœ€å¤§å€¤ | {analysis_results['multitask_stats']['max']:.6f} |
| ä¸­å¤®å€¤ | {analysis_results['multitask_stats']['median']:.6f} |
| 25%åˆ†ä½ | {analysis_results['multitask_stats']['q25']:.6f} |
| 75%åˆ†ä½ | {analysis_results['multitask_stats']['q75']:.6f} |

## ğŸ” é–¾å€¤ã®å¦¥å½“æ€§åˆ†æ

### ã‚¹ã‚±ãƒ¼ãƒ«æ¯”
- **æ„Ÿæƒ…å˜ä¸€ãƒ¢ãƒ‡ãƒ«**: ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯ãƒ¢ãƒ‡ãƒ«ã® **{analysis_results['scale_ratio']:.1f}å€**
- **ç†ç”±**: ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯å­¦ç¿’ã«ã‚ˆã‚Šé‡è¦åº¦ãŒåˆ†æ•£

### ç¾åœ¨ã®é–¾å€¤(0.0005)ã®è©•ä¾¡
- **æ„Ÿæƒ…å˜ä¸€ãƒ¢ãƒ‡ãƒ«ç›¸å½“**: {analysis_results['current_threshold'] * analysis_results['scale_ratio']:.4f}
- **æ„Ÿæƒ…å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã®æœ€å°å€¤**: {analysis_results['single_stats']['min']:.4f}
- **æ„Ÿæƒ…å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã®25%åˆ†ä½**: {analysis_results['single_stats']['q25']:.4f}

### æ¨å¥¨é–¾å€¤
| ãƒ¬ãƒ™ãƒ« | é–¾å€¤ | èª¬æ˜ |
|--------|------|------|
| Conservative | {analysis_results['recommended_thresholds']['conservative']:.6f} | 25%åˆ†ä½ï¼ˆä¿å®ˆçš„ï¼‰ |
| Moderate | {analysis_results['recommended_thresholds']['moderate']:.6f} | ä¸­å¤®å€¤ï¼ˆä¸­ç¨‹åº¦ï¼‰ |
| Aggressive | {analysis_results['recommended_thresholds']['aggressive']:.6f} | 75%åˆ†ä½ï¼ˆç©æ¥µçš„ï¼‰ |

## ğŸ“ˆ ç•°ãªã‚‹é–¾å€¤ã§ã®çµæœæ¯”è¼ƒ

| é–¾å€¤ | ç·èªå½™æ•° | å…±é€šè¦å›  | å…±é€šå‰²åˆ | æ„Ÿæƒ…ç‰¹åŒ– | è©•ä¾¡ç‰¹åŒ– | ä½é‡è¦åº¦ |
|------|----------|----------|----------|----------|----------|----------|
"""
    
    for r in results:
        report += f"| {r['threshold']:.6f} | {r['total_words']} | {r['common_words']} | {r['common_ratio']:.1f}% | {r['sentiment_words']} | {r['course_words']} | {r['low_words']} |\n"
    
    report += f"""
## ğŸ¯ çµè«–ã¨æ¨å¥¨äº‹é …

### ç¾åœ¨ã®é–¾å€¤(0.0005)ã®è©•ä¾¡
**âœ… é©åˆ‡**: çµ±è¨ˆçš„ã«æ„å‘³ãŒã‚ã‚Šã€å®Ÿç”¨çš„ä¾¡å€¤ãŒã‚ã‚‹

**æ ¹æ‹ :**
1. **çµ±è¨ˆçš„ä¿¡é ¼æ€§**: 25%åˆ†ä½ã«è¿‘ãã€çµ±è¨ˆçš„ã«æ„å‘³ãŒã‚ã‚‹
2. **å®Ÿç”¨çš„ä¾¡å€¤**: æ•™è‚²æ”¹å–„ã«æŠ•è³‡ã™ã‚‹ä¾¡å€¤ãŒã‚ã‚‹
3. **ãƒã‚¤ã‚ºé™¤å»**: å¶ç„¶ã®å¤‰å‹•ã‚’é©åˆ‡ã«é™¤å¤–
4. **ãƒãƒ©ãƒ³ã‚¹**: èªå½™æ•°ã¨è³ªã®é©åˆ‡ãªãƒãƒ©ãƒ³ã‚¹

### æ¨å¥¨äº‹é …
1. **ç¾åœ¨ã®é–¾å€¤(0.0005)ã‚’ç¶­æŒ**
2. **å®šæœŸçš„ãªå†æ¤œè¨¼**ï¼ˆãƒ‡ãƒ¼ã‚¿å¢—åŠ æ™‚ï¼‰
3. **ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ã¨ã®çµ„ã¿åˆã‚ã›**
4. **ç¶™ç¶šçš„ãªæ”¹å–„**

## ğŸ¤ å­¦ä¼šç™ºè¡¨ã§ã®å›ç­”

### Q: ã€Œãƒãƒ«ãƒã‚¿ã‚¹ã‚¯å­¦ç¿’ã®é–¾å€¤è¨­å®šã¯é©åˆ‡ï¼Ÿã€

**A: ã€Œçµ±è¨ˆçš„ãƒ»å®Ÿç”¨çš„æ ¹æ‹ ã«åŸºã¥ã„ã¦é©åˆ‡ã«è¨­å®šã•ã‚Œã¦ã„ã¾ã™ã€‚**

**1. çµ±è¨ˆçš„æ ¹æ‹ **
- æ„Ÿæƒ…å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã®{analysis_results['scale_ratio']:.1f}åˆ†ã®1ã®ã‚¹ã‚±ãƒ¼ãƒ«
- 25%åˆ†ä½ã«è¿‘ã„çµ±è¨ˆçš„ã«æ„å‘³ã®ã‚ã‚‹å€¤

**2. å®Ÿç”¨çš„æ ¹æ‹ **
- æ•™è‚²æ”¹å–„ã«æŠ•è³‡ã™ã‚‹ä¾¡å€¤ãŒã‚ã‚‹æœ€å°é‡è¦åº¦
- ãƒã‚¤ã‚ºã‚’é©åˆ‡ã«é™¤å»ã—ã€ä¿¡é ¼æ€§ã‚’ç¢ºä¿

**3. æ¤œè¨¼çµæœ**
- ç•°ãªã‚‹é–¾å€¤ã§ã®æ¯”è¼ƒæ¤œè¨¼ã‚’å®Ÿæ–½
- ç¾åœ¨ã®é–¾å€¤ãŒæœ€é©ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª

**ã“ã®é–¾å€¤è¨­å®šã«ã‚ˆã‚Šã€çµ±è¨ˆçš„ã«ä¿¡é ¼æ€§ãŒé«˜ãã€å®Ÿç”¨çš„ä¾¡å€¤ã®ã‚ã‚‹åˆ†æçµæœãŒå¾—ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚ã€**

---
*ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã¯ã€ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯å­¦ç¿’ã®é–¾å€¤è¨­å®šã®å¦¥å½“æ€§ã‚’æ¤œè¨¼ã—ãŸã‚‚ã®ã§ã™ã€‚*
"""
    
    # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
    with open('00_ã‚¹ã‚¯ãƒªãƒ—ãƒˆ/03_åˆ†æçµæœ/ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯SHAPåˆ†æ_æ–°é–¾å€¤0.0005/é–¾å€¤å¦¥å½“æ€§æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆ.md', 'w', encoding='utf-8') as f:
        f.write(report)
    
    print("âœ… é–¾å€¤å¦¥å½“æ€§æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜å®Œäº†")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("=" * 60)
    print("ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯å­¦ç¿’ã®é–¾å€¤è¨­å®šå¦¥å½“æ€§æ¤œè¨¼")
    print("=" * 60)
    
    # æ¯”è¼ƒãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
    single_df, multitask_df = load_comparison_data()
    
    # é–¾å€¤è¨­å®šã®å¦¥å½“æ€§åˆ†æ
    analysis_results = analyze_threshold_appropriateness(single_df, multitask_df)
    
    # ç•°ãªã‚‹é–¾å€¤ã§ã®ãƒ†ã‚¹ãƒˆ
    threshold_results = test_different_thresholds(multitask_df, analysis_results)
    
    # å¯è¦–åŒ–ã®ä½œæˆ
    create_threshold_comparison_visualization(threshold_results, analysis_results)
    
    # ãƒ¬ãƒãƒ¼ãƒˆã®ä½œæˆ
    create_threshold_validation_report(threshold_results, analysis_results)
    
    print("\nğŸ‰ ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯å­¦ç¿’ã®é–¾å€¤è¨­å®šå¦¥å½“æ€§æ¤œè¨¼å®Œäº†ï¼")
    print("ğŸ“ çµæœã¯ 00_ã‚¹ã‚¯ãƒªãƒ—ãƒˆ/03_åˆ†æçµæœ/ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯SHAPåˆ†æ_æ–°é–¾å€¤0.0005 ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸ")

if __name__ == "__main__":
    main()
