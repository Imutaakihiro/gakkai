### 背景
- 自由記述から授業評価スコアを予測したい。
- 評価は1〜4（1も含める）。
- 授業単位での分布（割合）と回答者数が手元にある。

### モデリング方針
- 順序性を活かすため、Ordinal Regression（CORAL型）を採用。
- 1〜4の4段階をそのまま扱う（順序回帰）。
  - 出力は3つのしきい値（ロジット）: y≥2, y≥3, y≥4
  - 累積確率: `p_ge2, p_ge3, p_ge4 = sigmoid(logits)`
  - 復元: `P(1)=1−p_ge2`, `P(2)=p_ge2−p_ge3`, `P(3)=p_ge3−p_ge4`, `P(4)=p_ge4`

### 学習データの想定
- 個票スコアがある場合: 通常の教師あり（順序回帰）。
- 個票スコアが無く授業ごとの分布のみの場合（LLP学習）:
  - LLP（Learning from Label Proportions）で授業内平均予測分布を、観測分布（1–4で正規化）へ近づける。

### 重み設計
- 個票あり（順序回帰）:
  - しきい値ごとの陽性不均衡に対し `pos_weight_k = N_neg_k / N_pos_k`（k∈{y≥2,y≥3,y≥4}）をBCEWithLogitsLossへ。
- 授業分布（LLP）:
  - 授業損失を回答者数で重み付け（信頼度の反映）。
  - 小規模授業は重みを小さく、または閾値で除外。

### 損失（LLP例）
- 授業bの平均予測分布 `p̄_b=[P1,P2,P3,P4]` と目標分布 `q_b=[q1,q2,q3,q4]` に対し、`loss_b = KL(q_b || p̄_b)` など。
- 全体損失は回答者数 `w_b` による加重平均。

### 評価指標
- 授業レベル: KL/JS/EMD、分布差の平均、最多カテゴリ一致率。
- 個票が一部あるなら: Accuracy、MAE、QWK、Within-1 Accuracy。

### 期待効果
- 順序性に反する不整合出力を構造的に抑止。
- 遠い誤り（1↔4）を減らし、安定した予測と解釈性を確保。
- 1が希少でも、1–4全体の整合的な学習が可能。

### 次アクション（授業単位マルチタスク学習の改善）
- Ordinalヘッド（y≥2,y≥3,y≥4）を既存マルチタスクモデルのスコア側タスクに導入。
- 授業分布LLP損失を追加し、回答者数で重み付け。
- 学習/検証の分割は授業単位でリーク防止。
- 指標（KL/QWK/MAE）を追加し、ログ保存・可視化。

### データ仕様・前処理（具体）
- 必須列（授業単位LLP学習）
  - `course_id`: 授業ID
  - `text`: 自由記述
  - `count_1, count_2, count_3, count_4` または `ratio_1, ratio_2, ratio_3, ratio_4`
  - `respondents`: 回答者数（= count_1+count_2+count_3+count_4）
- 正規化
  - 1–4の比率 `q1..q4` を合計=1に正規化
- データ分割
  - 授業単位で train/val/test を分割（同一 `course_id` がまたがらない）
  - 小規模授業は `respondents >= k`（例:30）でフィルタ or 低重み

### モデル実装詳細（スコア側タスク）
- 出力ヘッド: 3ロジット（累積確率）
  - `p_ge2 = σ(z1)`, `p_ge3 = σ(z2)`, `p_ge4 = σ(z3)` with monotonic constraint（`p_ge4 <= p_ge3 <= p_ge2` を誘導）
- クラス確率復元: `P1=1-p_ge2`, `P2=p_ge2-p_ge3`, `P3=p_ge3-p_ge4`, `P4=p_ge4`
- デコード
  - 予測クラス: `(p_ge2>=τ)+(p_ge3>=τ)+(p_ge4>=τ)+1`（τ=0.5 など）
  - 期待値: `E[y]=1*P1+2*P2+3*P3+4*P4`（評価/可視化に有用）

### LLP訓練手順（バッチ内集約）
- DataLoader 編成
  - ミニバッチ内に複数授業を含めつつ、各授業のテキストを複数件サンプル
  - 例: バッチサイズ=64、1授業あたり 4〜16 件を目安
- 集約
  - テキストごとの `P1..P4` を授業IDでグルーピング平均 → `p̄_b`
  - 目的分布 `q_b=[q1..q4]` と損失: `KL(q_b || p̄_b)` または `CE(q_b, p̄_b)`
- 重み付け
  - 授業重み `w_b = respondents_b`（安定性向上）
  - 最終損失: `(Σ_b w_b * loss_b) / (Σ_b w_b)`

### 監視・評価プロトコル
- 授業レベル
  - KL/JS、EMD（Wasserstein）、分布のL1/L2差、最多カテゴリ一致率
  - 期待値誤差: |E_q[y] − E_p̄[y]|、Spearman相関
- 個票サブセット（もし存在）
  - Accuracy、MAE、QWK、Within-1 Accuracy
- 早期終了 / モニタ
  - ValのKL（重み付き）を主指標、期待値MAEを副指標

### 推奨ハイパーパラメータ（初期値）
- 最適化: AdamW, lr=2e-5〜5e-5（BERT系）
- バッチ: 64（勾配累積で実効64を確保）
- 正則化: weight_decay=0.01、dropout=0.1
- 学習: 3〜5エポック、linear warmup 10%、early stopping patience=3
- 単調性の誘導（任意）
  - ペナルティ: `λ * (ReLU(p_ge4 − p_ge3) + ReLU(p_ge3 − p_ge2))`（λ=0.1〜1.0）

### 運用・推論
- 個票推論: 各テキストに対し `P1..P4` と期待値を出力
- 授業推論: 授業内平均で `p̄` を算出（評価時と同じ）
- 校正（任意）: 温度スケーリングを Val で学習して確率校正

### リスクと対策
- 小規模授業のノイズ: 回答者数重み／フィルタで緩和
- バッチにおける授業サンプル不足: サンプラーで各授業の最小サンプル数を確保
- 単調性違反: ペナルティ or 共有しきい値パラメータで抑制
- ドメイン偏り: 授業レベルの層化分割・コース属性で重み調整

### 追加拡張（将来）
- セミ教師あり: 一部個票ラベルで順序BCE、残りでLLPのハイブリッド損失
- マルチタスク化: 既存の感情スコアタスクと共有エンコーダで同時学習
- 解析: SHAPにより期待値/クラス確率への寄与を可視化
