# 2026年01月26日 実装フロー

**作成日**: 2026年1月26日  
**目的**: Daily/0126.mdのタスクを実装達成するための詳細フロー

---

## 📋 タスク一覧

### 今日の作業
1. マルチタスク学習の実行
2. SHAPの実装

### 課題・次回への引き継ぎ
3. 4点と2点の実態調査を実施する
4. SHAP分析時に不要な単語（助詞、格助詞）を除外する方法を検討
5. 精度向上よりも、寄与する単語の違いに焦点を当てた分析を進める

---

## 🎯 実装フロー

### タスク1: マルチタスク学習の実行

#### ステップ1: 環境の確認
- **目的**: 実行環境とリソースの確認
- **実行内容**:
  ```powershell
  # Python環境の確認
  python --version
  
  # 必要なライブラリの確認
  pip list | findstr "torch transformers shap"
  
  # データディレクトリの確認
  ls 01_データ
  ```
- **検証**: 必要なライブラリがインストールされているか、データファイルが存在するか
- **出力**: 環境確認レポート

#### ステップ2: データの準備
- **目的**: 学習用データの準備と前処理
- **実行内容**:
  - データファイルの読み込み
  - 授業単位での訓練・検証・テストセットの分割
  - データローダーの作成
- **検証**: データ分割が正しく行われているか（同一授業が複数セットにまたがっていないか）
- **出力**: データ分割レポート、データローダー

#### ステップ3: モデルの設定
- **目的**: マルチタスク学習モデルの設定
- **実行内容**:
  - モデルアーキテクチャの確認
    - BERTエンコーダー（共有）
    - OrdinalHead（P1, P2, P3, P4の確率分布予測）
    - sent_head（感情スコア予測）
  - ハイパーパラメータの設定
    - 学習率: 2e-5
    - バッチサイズ: 2
    - エポック数: 3
    - ALPHA_SENT: 0.3
  - 損失関数の設定
    - KL損失（OrdinalHead用、回答者数で重み付け）
    - MSE損失（sent_head用、重み0.3）
- **検証**: モデル構造が正しく設定されているか
- **出力**: モデル設定ファイル

#### ステップ4: 学習の実行
- **目的**: マルチタスク学習の実行
- **実行内容**:
  ```powershell
  cd 00_スクリプト
  python train_multitask_ordinal.py
  ```
- **検証**: 
  - 学習が正常に進行しているか（エラーがないか）
  - 学習曲線の確認（過学習の有無）
  - 検証データでの性能確認
- **出力**: 
  - 学習済みモデルファイル（`.pth`）
  - 学習ログ
  - 学習曲線グラフ

#### ステップ5: 結果の評価
- **目的**: 学習済みモデルの評価
- **実行内容**:
  - テストデータでの評価
  - メトリクスの計算
    - Test weighted KL損失
    - 期待値E[y]のRMSE、MAE、R²
    - 感情スコアのRMSE、MAE、R²
  - 結果の可視化
- **検証**: 評価結果が期待値を満たしているか
- **出力**: 
  - 評価レポート
  - 評価結果のグラフ

#### 完了条件
- ✅ 学習が正常に完了
- ✅ Test weighted KL損失が前回より改善または維持
- ✅ モデルファイルが保存されている
- ✅ 評価レポートが作成されている

---

### タスク2: SHAPの実装

#### ステップ1: SHAP分析の準備
- **目的**: SHAP分析の実行環境とデータの準備
- **実行内容**:
  - 学習済みモデルの読み込み
  - SHAPライブラリのインストール確認
  - 分析対象データの準備（サンプル数: 1,000件）
- **検証**: モデルが正しく読み込まれているか、データが準備されているか
- **出力**: 準備完了レポート

#### ステップ2: 不要な単語の除外機能の実装
- **目的**: 助詞・格助詞をSHAP分析から除外する機能の実装
- **参考**: 詳細な実装例は `その他/SHAP分析_不要単語除外_実装例.md` を参照
- **実行内容**:
  1. **助詞・格助詞リストの作成**
     - 日本語の助詞・格助詞のリストを作成
     - トークナイザー（BERT用）との整合性確認
     - 除外対象の単語IDを特定
  
  2. **除外機能の実装**
     - `create_stopword_ids()`: 助詞・格助詞のIDリスト作成
     - `filter_shap_values()`: SHAP値のフィルタリング
     - `create_word_importance_ranking()`: 重要語ランキング作成（除外機能付き）
     - 実装例を参考に、`analyze_ordinal_shap_production.py`に統合
  
  3. **テストの実施**
     - 除外機能が正しく動作するかテスト
     - 除外前後の比較
     - 重要語ランキングの変化を確認
- **検証**: 
  - 除外機能が正しく動作しているか
  - 除外された単語が適切か
- **出力**: 
  - 除外機能のコード
  - テスト結果レポート

#### ステップ3: SHAP分析の実行（P2とP4）
- **目的**: P2（2点確率）とP4（4点確率）のSHAP分析を実行
- **実行内容**:
  ```powershell
  cd 00_スクリプト
  python analyze_ordinal_shap_production.py
  ```
  - P2のSHAP分析: 2点を減らす要因を特定
  - P4のSHAP分析: 4点を増やす要因を特定
  - バックグラウンドデータの準備
  - SHAP値の計算
  - 不要な単語の除外（ステップ2で実装した機能を使用）
- **検証**: 
  - SHAP分析が正常に完了しているか
  - SHAP値が妥当か
  - 不要な単語が除外されているか
- **出力**: 
  - `word_importance_p2_production.csv`
  - `word_importance_p4_production.csv`
  - SHAP分析ログ

#### ステップ4: 結果の可視化
- **目的**: SHAP分析結果の可視化
- **実行内容**:
  - 重要語のランキング作成
  - トップ30要因の可視化
    - `p2_top30_factors_production.png`
    - `p4_top30_factors_production.png`
  - P2とP4の比較可視化
    - `p2_p4_comparison_production.png`
- **検証**: 可視化結果が正しく生成されているか
- **出力**: 可視化画像ファイル

#### ステップ5: 分析レポートの作成
- **目的**: SHAP分析結果のまとめとレポート作成
- **実行内容**:
  - 重要語リストの整理
  - 分析結果のサマリー作成
  - 気づきや示唆の記録
  - `ordinal_shap_analysis_summary_production.md`の作成
- **検証**: レポートが包括的で分かりやすいか
- **出力**: 分析レポート（Markdown形式）

#### 完了条件
- ✅ SHAP分析が正常に完了
- ✅ 不要な単語が除外されている
- ✅ 重要語リストが作成されている
- ✅ 可視化結果が生成されている
- ✅ 分析レポートが作成されている

---

### タスク3: 4点と2点の実態調査

#### ステップ1: データの抽出
- **目的**: 4点評価と2点評価のデータを抽出
- **実行内容**:
  ```python
  # 4点評価のデータ抽出
  data_4point = data[data['score'] == 4]
  
  # 2点評価のデータ抽出
  data_2point = data[data['score'] == 2]
  
  # 統計情報の確認
  print(f"4点評価の件数: {len(data_4point)}")
  print(f"2点評価の件数: {len(data_2point)}")
  ```
- **検証**: データ抽出が正しく行われているか
- **出力**: 
  - 4点評価データセット
  - 2点評価データセット
  - 統計情報レポート

#### ステップ2: 記述内容の分析
- **目的**: 4点と2点の記述内容を分析
- **実行内容**:
  1. **テキストの前処理**
     - テキストのクリーニング
     - トークン化
  
  2. **特徴的な単語の抽出**
     - TF-IDF分析
     - 単語頻度分析
     - 共起ネットワーク分析（必要に応じて）
  
  3. **フレーズ分析**
     - よく使われるフレーズの抽出
     - 文脈分析
- **検証**: 分析結果が妥当か
- **出力**: 
  - 特徴的な単語リスト
  - フレーズ分析結果

#### ステップ3: 比較分析
- **目的**: 4点と2点の記述内容を比較
- **実行内容**:
  1. **共通点の特定**
     - 両方に出現する単語・フレーズ
     - 類似する文脈
  
  2. **相違点の特定**
     - 4点にのみ出現する単語・フレーズ
     - 2点にのみ出現する単語・フレーズ
     - 文脈の違い
  
  3. **定量的分析**
     - 単語頻度の比較
     - 文の長さの比較
     - 感情スコアの比較
- **検証**: 比較結果が妥当か
- **出力**: 
  - 比較分析レポート
  - 可視化結果（必要に応じて）

#### ステップ4: レポートの作成
- **目的**: 実態調査結果のまとめ
- **実行内容**:
  - 調査結果のまとめ
  - 重要な発見の記録
  - 可視化（必要に応じて）
- **検証**: レポートが包括的で分かりやすいか
- **出力**: 実態調査レポート（Markdown形式）

#### 完了条件
- ✅ 4点と2点のデータが抽出されている
- ✅ 記述内容の分析が完了している
- ✅ 比較分析が完了している
- ✅ レポートが作成されている

---

## 🔄 達成・分析・完了のサイクル

### サイクルの流れ

```
┌─────────────────┐
│  1. タスク理解   │
│  Dailyメモ読み取り│
│  現状確認        │
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│  2. 実装フロー   │
│  詳細ステップ作成│
│  実行計画作成    │
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│  3. 実装実行     │
│  コード実行      │
│  中間検証        │
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│  4. 結果分析     │
│  結果収集        │
│  分析実施        │
│  可視化          │
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│  5. 完了報告     │
│  Daily更新       │
│  レポート作成    │
│  次ステップ提案  │
└─────────────────┘
```

### 各フェーズでのチェックポイント

#### フェーズ1: タスク理解
- [ ] Dailyメモが正しく読み取れているか
- [ ] タスクが具体的に分解されているか
- [ ] 現状が正しく把握されているか

#### フェーズ2: 実装フロー
- [ ] 実装ステップが詳細に定義されているか
- [ ] 各ステップの入力・出力が明確か
- [ ] 検証方法が定義されているか

#### フェーズ3: 実装実行
- [ ] 各ステップが正常に実行されているか
- [ ] 中間検証が実施されているか
- [ ] エラーが適切に処理されているか

#### フェーズ4: 結果分析
- [ ] 結果が正しく収集されているか
- [ ] 分析が適切に実施されているか
- [ ] 可視化が作成されているか

#### フェーズ5: 完了報告
- [ ] Dailyメモが更新されているか
- [ ] レポートが作成されているか
- [ ] 次のステップが提案されているか

---

## 📊 進捗管理

### タスクの進捗状況

| タスク | ステータス | 進捗率 | 備考 |
|--------|-----------|--------|------|
| 1. マルチタスク学習の実行 | ⏳ 未開始 | 0% | - |
| 2. SHAPの実装 | ⏳ 進行中 | 50% | 不要な単語の除外機能を実装完了 |
| 3. 4点と2点の実態調査 | ⏳ 未開始 | 0% | - |
| 4. 不要な単語の除外機能 | ✅ 完了 | 100% | `analyze_ordinal_shap_production.py`に実装完了 |
| 5. 寄与する単語の違いに焦点 | ⏳ 未開始 | 0% | タスク2の一部 |

### ステータス記号
- ✅ 完了
- ⏳ 進行中
- ⏸️ 一時停止
- ❌ 失敗
- 🔄 再実行中

---

## 🎯 優先順位

### 最優先（今すぐ実行）
1. **タスク2: SHAPの実装**（特にステップ2: 不要な単語の除外機能）
   - 理由: 他の分析タスクの前提となる
   - 推定時間: 2-3時間

### 高優先（SHAP実装後）
2. **タスク1: マルチタスク学習の実行**
   - 理由: モデルの再学習が必要な場合に備える
   - 推定時間: 1-2時間

3. **タスク3: 4点と2点の実態調査**
   - 理由: SHAP分析結果と合わせて理解を深める
   - 推定時間: 2-3時間

---

## 📝 実行ログ

### 実行記録

#### 2026年1月26日
- **不要な単語の除外機能の実装完了** (時刻: 実装中)
  - `analyze_ordinal_shap_production.py`に以下の機能を追加:
    - `create_stopword_ids()`: 助詞・格助詞のIDリスト作成
    - SHAP分析時に不要な単語を自動除外
    - 除外されたトークン数の記録とレポート出力
  - 実装内容:
    - 日本語の助詞・格助詞リストを作成
    - トークナイザーでエンコードしてIDを取得
    - SHAP値の計算時に不要な単語を除外
    - 除外されたトークン数を記録してレポートに含める

### エラーログ
（エラー発生時に記録）

### 気づき・発見
- 不要な単語の除外機能により、SHAP分析の結果がより意味のある単語に焦点を当てられるようになった
- 助詞・格助詞を除外することで、実質的な要因分析が可能になる

---

## 🔗 関連ファイル

- `Daily/0126.md`: 今日のDailyメモ
- `その他/現状整理_順序回帰実験_202501.md`: 現状整理
- `その他/授業単位マルチタスク_順序回帰LLP計画.md`: 計画書
- `その他/SHAP分析_不要単語除外_実装例.md`: SHAP分析の不要単語除外機能の実装例
- `.cursor/agents/task-implementer.md`: AIエージェント設定

---

**最終更新**: 2026年1月26日
