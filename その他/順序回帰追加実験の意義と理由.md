# 順序回帰追加実験の意義と理由

**作成日**: 2025年1月  
**目的**: マルチタスク学習の結果がある中で、順序回帰を追加実験として行う理由を明確化

---

## 📊 既存のマルチタスク学習の結果

### 完了している実験
- ✅ マルチタスクモデル: 感情スコア + 授業評価スコアの同時予測
- ✅ SHAP分析完了: 満足度要因の特定（577語彙、19.4%）
- ✅ 重要な発見: 「面白さが最重要要因」など

### マルチタスク学習の限界
1. **性能の低下**
   - 感情分析精度: 77.0% → 72.5%（-4.5%低下）
   - 評価スコア予測: R² = 0.016 → R² = -0.108（悪化）
   - **タスク間干渉**により両方の性能が悪化

2. **モデリングの課題**
   - 評価スコア（1～4）を連続値として扱っている
   - **順序性が考慮されていない**（1と4の誤りが同じ重み）
   - 個人→集団平均予測の困難性（R²≈0）

---

## 🎯 順序回帰を追加実験として行う理由

### 1. **方法論的改善の実証**

#### マルチタスク学習の問題点
- 評価スコアを連続値（回帰）として扱う
- 1と4の誤りが同じ重み（順序性を無視）
- タスク間干渉による性能低下

#### 順序回帰の利点
- **順序性を構造的に保証**: 1→2→3→4の順序を尊重
- **遠い誤りを減らす**: 1↔4の誤りを構造的に抑制
- **確率分布を直接予測**: P1～P4の分布を直接学習
- **LLP学習**: 授業単位の分布を直接学習（個票不要）

### 2. **卒論での方法論的貢献**

#### 研究の流れ
1. **単一タスクモデル**: 各タスクを個別に学習
2. **マルチタスクモデル**: 複数タスクを同時学習（限界を発見）
3. **順序回帰モデル**: より適切なモデリング手法の提案 ← **ここ**

#### 卒論での位置づけ
- **問題提起**: マルチタスク学習の限界を発見
- **解決策の提案**: 順序回帰による改善
- **実証**: 順序回帰の有効性を実証

### 3. **実用的な改善提案**

#### マルチタスク学習ではできないこと
- ❌ 評価スコアの確率分布（P1～P4）を直接予測
- ❌ 期待値E[y]の計算
- ❌ 順序性を保証した予測

#### 順序回帰で可能になること
- ✅ 評価スコアの確率分布（P1～P4）を直接予測
- ✅ 期待値E[y] = 1×P1 + 2×P2 + 3×P3 + 4×P4の計算
- ✅ 順序性を保証した予測（1↔4の誤りを抑制）
- ✅ 授業単位の分布を直接学習（LLP）

### 4. **SHAP分析の深化**

#### マルチタスク学習のSHAP分析
- 感情スコアへの寄与
- 授業評価スコアへの寄与
- **限界**: 評価スコアが連続値のため、段階別の要因分析が困難

#### 順序回帰のSHAP分析
- 感情スコアへの寄与
- 授業評価スコアへの寄与
- **期待値E[y]への寄与** ← 新規
- **P1（低評価確率）への寄与** ← 新規
- **P2（中低評価確率）への寄与** ← 新規
- **P3（中高評価確率）への寄与** ← 新規
- **P4（高評価確率）への寄与** ← 新規

**意義**: 各評価段階での要因を詳細に分析可能

---

## 📈 期待される成果

### 1. **方法論的貢献**
- マルチタスク学習の限界を補完する手法の提案
- 順序回帰による改善の実証
- 卒論での方法論的貢献

### 2. **実用的な改善**
- より適切なモデリング手法の提案
- 評価スコアの確率分布を直接予測
- 期待値E[y]の計算による解釈性の向上

### 3. **分析の深化**
- 各評価段階（P1～P4）での要因分析
- 期待値E[y]への寄与分析
- より詳細な満足度要因の特定

---

## 🔄 研究の流れ（卒論での位置づけ）

### 第1段階: 単一タスクモデル
- 感情分析: Accuracy 77.0%
- 評価スコア予測: R² = 0.016（困難）

### 第2段階: マルチタスクモデル
- **発見**: タスク間干渉による性能低下
- **限界**: 評価スコア予測が困難（R²≈0）
- **成果**: 満足度要因の特定（SHAP分析）

### 第3段階: 順序回帰モデル ← **追加実験**
- **目的**: マルチタスク学習の限界を補完
- **改善**: 順序性を考慮したモデリング
- **成果**: 
  - 確率分布（P1～P4）の直接予測
  - 期待値E[y]の計算
  - 各評価段階での要因分析

---

## 💡 卒論での記述例

### 序論・背景
「マルチタスク学習により、感情分析と評価スコア予測を同時に行うことができたが、タスク間干渉による性能低下が観察された。また、評価スコア（1～4）を連続値として扱うことで、順序性が考慮されていないという課題があった。」

### 提案手法
「これらの課題を解決するため、順序回帰（Ordinal Regression）を採用した。順序回帰により、評価スコアの順序性を構造的に保証し、確率分布（P1～P4）を直接予測することが可能になる。」

### 実験結果
「順序回帰モデルにより、各評価段階（P1～P4）での要因を詳細に分析することができた。また、期待値E[y]の計算により、より解釈可能な予測が可能になった。」

---

## ✅ 結論

順序回帰を追加実験として行う理由：

1. **方法論的改善の実証**: マルチタスク学習の限界を補完
2. **卒論での方法論的貢献**: より適切なモデリング手法の提案
3. **実用的な改善**: 確率分布の直接予測、期待値の計算
4. **分析の深化**: 各評価段階での要因分析

**順序回帰は、マルチタスク学習の「上位互換」ではなく、「補完的手法」として位置づけるべき。**

---

**最終更新**: 2025年1月

