import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np
from matplotlib import font_manager
import warnings
warnings.filterwarnings('ignore')

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã®è¨­å®šï¼ˆç¢ºå®Ÿç‰ˆï¼‰
def setup_japanese_font():
    """æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã®è¨­å®š"""
    import matplotlib.font_manager as fm
    
    # Windowsç’°å¢ƒã§ã®æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
    try:
        # åˆ©ç”¨å¯èƒ½ãªãƒ•ã‚©ãƒ³ãƒˆã‚’å–å¾—
        available_fonts = [f.name for f in fm.fontManager.ttflist]
        print("åˆ©ç”¨å¯èƒ½ãªãƒ•ã‚©ãƒ³ãƒˆ:", available_fonts[:10])  # æœ€åˆã®10å€‹ã‚’è¡¨ç¤º
        
        # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã®å„ªå…ˆé †ä½
        japanese_fonts = [
            'MS Gothic', 'MS Mincho', 'Yu Gothic', 'Meiryo', 'Hiragino Sans',
            'Takao', 'IPAexGothic', 'IPAPGothic', 'VL PGothic', 'Noto Sans CJK JP',
            'DejaVu Sans', 'Arial Unicode MS'
        ]
        
        # åˆ©ç”¨å¯èƒ½ãªæ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã‚’æ¢ã™
        for font in japanese_fonts:
            if font in available_fonts:
                plt.rcParams['font.family'] = font
                plt.rcParams['axes.unicode_minus'] = False
                print(f"âœ… æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®šå®Œäº†: {font}")
                return True
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è¨­å®š
        plt.rcParams['font.family'] = 'DejaVu Sans'
        plt.rcParams['axes.unicode_minus'] = False
        print("âš ï¸ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ•ã‚©ãƒ³ãƒˆè¨­å®š")
        return False
        
    except Exception as e:
        print(f"âŒ ãƒ•ã‚©ãƒ³ãƒˆè¨­å®šã‚¨ãƒ©ãƒ¼: {e}")
        plt.rcParams['font.family'] = 'DejaVu Sans'
        plt.rcParams['axes.unicode_minus'] = False
        return False

# ãƒ•ã‚©ãƒ³ãƒˆè¨­å®šå®Ÿè¡Œ
font_success = setup_japanese_font()

# è¿½åŠ ã®ãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
if not font_success:
    print("ğŸ”§ è¿½åŠ ã®ãƒ•ã‚©ãƒ³ãƒˆè¨­å®šã‚’è©¦è¡Œä¸­...")
    try:
        # Windowsæ¨™æº–ãƒ•ã‚©ãƒ³ãƒˆã‚’ç›´æ¥æŒ‡å®š
        plt.rcParams['font.family'] = ['MS Gothic', 'MS Mincho', 'Yu Gothic', 'Meiryo', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        print("âœ… è¿½åŠ è¨­å®šå®Œäº†")
    except:
        print("âŒ è¿½åŠ è¨­å®šã‚‚å¤±æ•—")

# ã‚°ãƒ©ãƒ•ã®ã‚¹ã‚¿ã‚¤ãƒ«è¨­å®š
plt.style.use('default')  # seaborn-v0_8ã‚’å‰Šé™¤ã—ã¦ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã«
sns.set_palette("husl")

# ãƒ•ã‚©ãƒ³ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ã‚¯ãƒªã‚¢
try:
    font_manager._rebuild()
    print("ğŸ”„ ãƒ•ã‚©ãƒ³ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ")
except:
    print("âš ï¸ ãƒ•ã‚©ãƒ³ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ã‚¯ãƒªã‚¢ã«å¤±æ•—")

# ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
if font_success:
    # æ—¥æœ¬èªãƒ©ãƒ™ãƒ«
    data = {
        'ã‚«ãƒ†ã‚´ãƒª': ['å…±é€šè¦å› ', 'æ„Ÿæƒ…ç‰¹åŒ–', 'è©•ä¾¡ç‰¹åŒ–', 'ä½é‡è¦åº¦'],
        'èªå½™æ•°': [577, 1200, 532, 889],
        'å‰²åˆ': [19.4, 40.3, 17.9, 22.4],
        'å¹³å‡æ„Ÿæƒ…é‡è¦åº¦': [0.000727, 0.000770, 0.000302, 0.000313],
        'å¹³å‡è©•ä¾¡é‡è¦åº¦': [0.000695, 0.000289, 0.000707, 0.000298],
        'å¹³å‡çµ±åˆé‡è¦åº¦': [0.001422, 0.001059, 0.001009, 0.000610]
    }
    print("âœ… æ—¥æœ¬èªãƒ©ãƒ™ãƒ«ã§å®Ÿè¡Œ")
else:
    # è‹±èªãƒ©ãƒ™ãƒ«ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
    data = {
        'ã‚«ãƒ†ã‚´ãƒª': ['Common Factors', 'Sentiment Specific', 'Evaluation Specific', 'Low Importance'],
        'èªå½™æ•°': [577, 1200, 532, 889],
        'å‰²åˆ': [19.4, 40.3, 17.9, 22.4],
        'å¹³å‡æ„Ÿæƒ…é‡è¦åº¦': [0.000727, 0.000770, 0.000302, 0.000313],
        'å¹³å‡è©•ä¾¡é‡è¦åº¦': [0.000695, 0.000289, 0.000707, 0.000298],
        'å¹³å‡çµ±åˆé‡è¦åº¦': [0.001422, 0.001059, 0.001009, 0.000610]
    }
    print("âš ï¸ è‹±èªãƒ©ãƒ™ãƒ«ã§å®Ÿè¡Œï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰")

df = pd.DataFrame(data)

# è‰²ã®è¨­å®šï¼ˆæ”¹å–„ç‰ˆï¼‰
colors = ['#E74C3C', '#3498DB', '#2ECC71', '#F39C12']  # ã‚ˆã‚Šé®®ã‚„ã‹ã§è¦‹ã‚„ã™ã„è‰²
colors_light = ['#F1948A', '#85C1E9', '#82E0AA', '#F7DC6F']  # è–„ã„è‰²
colors_gradient = ['#FF4757', '#3742FA', '#2ED573', '#FFA502']  # ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³è‰²

# å›³ã®ã‚µã‚¤ã‚ºè¨­å®š
fig = plt.figure(figsize=(20, 15))
fig.patch.set_facecolor('white')

# ã‚¿ã‚¤ãƒˆãƒ«ã®è¨­å®š
if font_success:
    title1 = 'ã‚«ãƒ†ã‚´ãƒªåˆ¥èªå½™æ•°åˆ†å¸ƒ'
    title2 = 'ã‚«ãƒ†ã‚´ãƒªåˆ¥å‰²åˆåˆ†å¸ƒ'
    title3 = 'ã‚«ãƒ†ã‚´ãƒªåˆ¥é‡è¦åº¦æ¯”è¼ƒ'
    title4 = 'å…±é€šè¦å› TOP10'
    title5 = 'æ„Ÿæƒ…ç‰¹åŒ–è¦å› TOP10'
    title6 = 'è©•ä¾¡ç‰¹åŒ–è¦å› TOP10'
    xlabel = 'ã‚«ãƒ†ã‚´ãƒª'
    ylabel = 'é‡è¦åº¦'
    hlabel = 'çµ±åˆé‡è¦åº¦'
    legend1 = 'æ„Ÿæƒ…é‡è¦åº¦'
    legend2 = 'è©•ä¾¡é‡è¦åº¦'
    legend3 = 'çµ±åˆé‡è¦åº¦'
else:
    title1 = 'Vocabulary Distribution by Category'
    title2 = 'Percentage Distribution by Category'
    title3 = 'Importance Comparison by Category'
    title4 = 'Top 10 Common Factors'
    title5 = 'Top 10 Sentiment-Specific Factors'
    title6 = 'Top 10 Evaluation-Specific Factors'
    xlabel = 'Category'
    ylabel = 'Importance'
    hlabel = 'Total Importance'
    legend1 = 'Sentiment Importance'
    legend2 = 'Evaluation Importance'
    legend3 = 'Total Importance'

# 1. ã‚«ãƒ†ã‚´ãƒªåˆ¥èªå½™æ•°ã®å††ã‚°ãƒ©ãƒ•
plt.subplot(2, 3, 1)
wedges, texts, autotexts = plt.pie(df['èªå½™æ•°'], labels=df['ã‚«ãƒ†ã‚´ãƒª'], autopct='%1.1f%%', 
                                  colors=colors, startangle=90, explode=(0.05, 0.05, 0.05, 0.05))
plt.title(title1, fontsize=16, fontweight='bold', pad=20, color='#2C3E50')
plt.axis('equal')

# 2. ã‚«ãƒ†ã‚´ãƒªåˆ¥å‰²åˆã®å††ã‚°ãƒ©ãƒ•
plt.subplot(2, 3, 2)
wedges, texts, autotexts = plt.pie(df['å‰²åˆ'], labels=df['ã‚«ãƒ†ã‚´ãƒª'], autopct='%1.1f%%', 
                                  colors=colors_gradient, startangle=90, explode=(0.05, 0.05, 0.05, 0.05))
plt.title(title2, fontsize=16, fontweight='bold', pad=20, color='#2C3E50')
plt.axis('equal')

# 3. é‡è¦åº¦ã®æ¯”è¼ƒï¼ˆæ£’ã‚°ãƒ©ãƒ•ï¼‰
plt.subplot(2, 3, 3)
x = np.arange(len(df['ã‚«ãƒ†ã‚´ãƒª']))
width = 0.25

bars1 = plt.bar(x - width, df['å¹³å‡æ„Ÿæƒ…é‡è¦åº¦'], width, label=legend1, 
                color=colors[0], alpha=0.8, edgecolor='black', linewidth=0.5)
bars2 = plt.bar(x, df['å¹³å‡è©•ä¾¡é‡è¦åº¦'], width, label=legend2, 
                color=colors[1], alpha=0.8, edgecolor='black', linewidth=0.5)
bars3 = plt.bar(x + width, df['å¹³å‡çµ±åˆé‡è¦åº¦'], width, label=legend3, 
                color=colors[2], alpha=0.8, edgecolor='black', linewidth=0.5)

plt.xlabel(xlabel, fontsize=12, fontweight='bold')
plt.ylabel(ylabel, fontsize=12, fontweight='bold')
plt.title(title3, fontsize=16, fontweight='bold', color='#2C3E50')
plt.xticks(x, df['ã‚«ãƒ†ã‚´ãƒª'], rotation=45, fontweight='bold')
plt.legend(fontsize=10)
plt.grid(True, alpha=0.3, linestyle='--')

# 4. å…±é€šè¦å› TOP10ã®é‡è¦åº¦ï¼ˆæ¨ªæ£’ã‚°ãƒ©ãƒ•ï¼‰
plt.subplot(2, 3, 4)
common_factors = {
    'å­¦ã¶': 0.002664,
    'myit': 0.002468,
    'ã¾ã¾': 0.002404,
    'é›»å‹•': 0.002369,
    'ã™ã': 0.002283,
    'ã‚ˆã‚Š': 0.002239,
    'å˜èªèª': 0.002198,
    'æ–¹å¼': 0.002111,
    'ã‚Œã‚‹': 0.001983,
    'ä¸‹ã•ã„': 0.001974
}

words = list(common_factors.keys())
values = list(common_factors.values())

bars = plt.barh(words, values, color=colors[0], alpha=0.8, edgecolor='black', linewidth=0.5)
plt.xlabel(hlabel, fontsize=12, fontweight='bold')
plt.title(title4, fontsize=16, fontweight='bold', color='#2C3E50')
plt.grid(True, alpha=0.3, linestyle='--')

# 5. æ„Ÿæƒ…ç‰¹åŒ–è¦å› TOP10ã®é‡è¦åº¦ï¼ˆæ¨ªæ£’ã‚°ãƒ©ãƒ•ï¼‰
plt.subplot(2, 3, 5)
sentiment_factors = {
    'ä»£ã‚ã‚Š': 0.001951,
    'æŒã£ã‘': 0.001934,
    'å¿˜ã‚Œç‰©': 0.001823,
    'ã¾ã™æ›¸': 0.001808,
    'ç„¦ç‚¹': 0.001768,
    'çµ„ã‚€': 0.001760,
    'ç´ å­': 0.001745,
    'è‹±èªã¹': 0.001732,
    'å‰å›': 0.001726,
    'å…¥åŠ›': 0.001722
}

words_sent = list(sentiment_factors.keys())
values_sent = list(sentiment_factors.values())

bars = plt.barh(words_sent, values_sent, color=colors[1], alpha=0.8, edgecolor='black', linewidth=0.5)
plt.xlabel(hlabel, fontsize=12, fontweight='bold')
plt.title(title5, fontsize=16, fontweight='bold', color='#2C3E50')
plt.grid(True, alpha=0.3, linestyle='--')

# 6. è©•ä¾¡ç‰¹åŒ–è¦å› TOP10ã®é‡è¦åº¦ï¼ˆæ¨ªæ£’ã‚°ãƒ©ãƒ•ï¼‰
plt.subplot(2, 3, 6)
evaluation_factors = {
    'ç¬¦å·': 0.001779,
    'è¿‘ã¥ã„': 0.001769,
    'åŸºç¤': 0.001690,
    'äººæ': 0.001638,
    'ãŠã‘': 0.001636,
    'ã¨ã‚‰': 0.001620,
    'å½“ã¦': 0.001541,
    'æ¯”ã¹': 0.001528,
    'ã•ã¾ã–ã¾': 0.001517,
    'ãŠã‘ä¸ˆå¤«': 0.001493
}

words_eval = list(evaluation_factors.keys())
values_eval = list(evaluation_factors.values())

bars = plt.barh(words_eval, values_eval, color=colors[2], alpha=0.8, edgecolor='black', linewidth=0.5)
plt.xlabel(hlabel, fontsize=12, fontweight='bold')
plt.title(title6, fontsize=16, fontweight='bold', color='#2C3E50')
plt.grid(True, alpha=0.3, linestyle='--')

# ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã®èª¿æ•´
plt.tight_layout(pad=3.0)

# ä¿å­˜
plt.savefig('ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯SHAPåˆ†æ_å¯è¦–åŒ–çµæœ.png', dpi=300, bbox_inches='tight')
plt.show()

# å€‹åˆ¥ã®å††ã‚°ãƒ©ãƒ•ã‚‚ä½œæˆ
fig2, axes = plt.subplots(1, 2, figsize=(15, 6))
fig2.patch.set_facecolor('white')

# èªå½™æ•°ã®å††ã‚°ãƒ©ãƒ•
wedges1, texts1, autotexts1 = axes[0].pie(df['èªå½™æ•°'], labels=df['ã‚«ãƒ†ã‚´ãƒª'], autopct='%1.1f%%', 
                                         colors=colors, startangle=90, explode=(0.05, 0.05, 0.05, 0.05))
axes[0].set_title(title1, fontsize=16, fontweight='bold', color='#2C3E50')
axes[0].axis('equal')

# å‰²åˆã®å††ã‚°ãƒ©ãƒ•
wedges2, texts2, autotexts2 = axes[1].pie(df['å‰²åˆ'], labels=df['ã‚«ãƒ†ã‚´ãƒª'], autopct='%1.1f%%', 
                                         colors=colors_gradient, startangle=90, explode=(0.05, 0.05, 0.05, 0.05))
axes[1].set_title(title2, fontsize=16, fontweight='bold', color='#2C3E50')
axes[1].axis('equal')

plt.tight_layout()
plt.savefig('ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯SHAPåˆ†æ_å††ã‚°ãƒ©ãƒ•.png', dpi=300, bbox_inches='tight')
plt.show()

# çµ±è¨ˆæƒ…å ±ã®è¡¨ç¤º
if font_success:
    print("=== ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯SHAPåˆ†æã®çµ±è¨ˆæƒ…å ± ===")
    print(f"ç·èªå½™æ•°: {df['èªå½™æ•°'].sum()}")
    print(f"å…±é€šè¦å› : {df.loc[0, 'èªå½™æ•°']}èªå½™ ({df.loc[0, 'å‰²åˆ']}%)")
    print(f"æ„Ÿæƒ…ç‰¹åŒ–: {df.loc[1, 'èªå½™æ•°']}èªå½™ ({df.loc[1, 'å‰²åˆ']}%)")
    print(f"è©•ä¾¡ç‰¹åŒ–: {df.loc[2, 'èªå½™æ•°']}èªå½™ ({df.loc[2, 'å‰²åˆ']}%)")
    print(f"ä½é‡è¦åº¦: {df.loc[3, 'èªå½™æ•°']}èªå½™ ({df.loc[3, 'å‰²åˆ']}%)")
    print("\n=== é‡è¦åº¦ã®ç‰¹å¾´ ===")
    print(f"å…±é€šè¦å› ã®å¹³å‡çµ±åˆé‡è¦åº¦: {df.loc[0, 'å¹³å‡çµ±åˆé‡è¦åº¦']:.6f}")
    print(f"æ„Ÿæƒ…ç‰¹åŒ–ã®å¹³å‡çµ±åˆé‡è¦åº¦: {df.loc[1, 'å¹³å‡çµ±åˆé‡è¦åº¦']:.6f}")
    print(f"è©•ä¾¡ç‰¹åŒ–ã®å¹³å‡çµ±åˆé‡è¦åº¦: {df.loc[2, 'å¹³å‡çµ±åˆé‡è¦åº¦']:.6f}")
    print(f"ä½é‡è¦åº¦ã®å¹³å‡çµ±åˆé‡è¦åº¦: {df.loc[3, 'å¹³å‡çµ±åˆé‡è¦åº¦']:.6f}")
    print("\n=== è©³ç´°ãƒ‡ãƒ¼ã‚¿ ===")
else:
    print("=== Multitask SHAP Analysis Statistics ===")
    print(f"Total Vocabulary: {df['èªå½™æ•°'].sum()}")
    print(f"Common Factors: {df.loc[0, 'èªå½™æ•°']} words ({df.loc[0, 'å‰²åˆ']}%)")
    print(f"Sentiment Specific: {df.loc[1, 'èªå½™æ•°']} words ({df.loc[1, 'å‰²åˆ']}%)")
    print(f"Evaluation Specific: {df.loc[2, 'èªå½™æ•°']} words ({df.loc[2, 'å‰²åˆ']}%)")
    print(f"Low Importance: {df.loc[3, 'èªå½™æ•°']} words ({df.loc[3, 'å‰²åˆ']}%)")
    print("\n=== Importance Characteristics ===")
    print(f"Common Factors Avg Total Importance: {df.loc[0, 'å¹³å‡çµ±åˆé‡è¦åº¦']:.6f}")
    print(f"Sentiment Specific Avg Total Importance: {df.loc[1, 'å¹³å‡çµ±åˆé‡è¦åº¦']:.6f}")
    print(f"Evaluation Specific Avg Total Importance: {df.loc[2, 'å¹³å‡çµ±åˆé‡è¦åº¦']:.6f}")
    print(f"Low Importance Avg Total Importance: {df.loc[3, 'å¹³å‡çµ±åˆé‡è¦åº¦']:.6f}")
    print("\n=== Detailed Data ===")

print(df.to_string(index=False))
