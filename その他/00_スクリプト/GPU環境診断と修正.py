#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GPUç’°å¢ƒè¨ºæ–­ã¨ä¿®æ­£ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
æ ¹æœ¬åŸå› ã‚’ç‰¹å®šã—ã€GPUä½¿ç”¨ã‚’å¯èƒ½ã«ã™ã‚‹
"""

import torch
import subprocess
import sys
import os

def check_gpu_environment():
    """GPUç’°å¢ƒã‚’è©³ç´°ã«è¨ºæ–­"""
    print("ğŸ” GPUç’°å¢ƒè¨ºæ–­ã‚’é–‹å§‹...")
    print("="*60)
    
    # 1. PyTorchæƒ…å ±
    print(f"ğŸ“¦ PyTorch version: {torch.__version__}")
    print(f"ğŸ“¦ PyTorch CUDA available: {torch.cuda.is_available()}")
    
    if torch.cuda.is_available():
        print(f"ğŸ® CUDA version: {torch.version.cuda}")
        print(f"ğŸ® GPU count: {torch.cuda.device_count()}")
        for i in range(torch.cuda.device_count()):
            print(f"ğŸ® GPU {i}: {torch.cuda.get_device_name(i)}")
            print(f"ğŸ® GPU {i} memory: {torch.cuda.get_device_properties(i).total_memory / 1024**3:.1f} GB")
    else:
        print("âŒ CUDA not available")
    
    # 2. DirectMLç¢ºèª
    try:
        import torch_directml
        print(f"ğŸ”„ DirectML available: {torch_directml.is_available()}")
        if torch_directml.is_available():
            print(f"ğŸ”„ DirectML device: {torch_directml.device()}")
    except ImportError:
        print("ğŸ”„ DirectML not installed")
    
    # 3. NVIDIAæƒ…å ±
    try:
        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)
        if result.returncode == 0:
            print("âœ… NVIDIA driver detected")
            print(result.stdout)
        else:
            print("âŒ NVIDIA driver not found")
    except FileNotFoundError:
        print("âŒ nvidia-smi not found")
    
    # 4. ç’°å¢ƒå¤‰æ•°ç¢ºèª
    print("\nğŸŒ Environment variables:")
    cuda_vars = ['CUDA_VISIBLE_DEVICES', 'CUDA_HOME', 'CUDA_PATH']
    for var in cuda_vars:
        value = os.environ.get(var, 'Not set')
        print(f"  {var}: {value}")
    
    return torch.cuda.is_available()

def fix_gpu_environment():
    """GPUç’°å¢ƒã‚’ä¿®æ­£"""
    print("\nğŸ› ï¸ GPUç’°å¢ƒä¿®æ­£ã‚’è©¦è¡Œ...")
    
    # 1. DirectMLã‚’ç„¡åŠ¹åŒ–
    os.environ['PYTORCH_DISABLE_DIRECTML'] = '1'
    print("âœ… DirectML disabled")
    
    # 2. CUDAç’°å¢ƒå¤‰æ•°ã‚’è¨­å®š
    os.environ['CUDA_VISIBLE_DEVICES'] = '0'
    print("âœ… CUDA_VISIBLE_DEVICES set to 0")
    
    # 3. PyTorchã®ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚’å¼·åˆ¶è¨­å®š
    try:
        torch.backends.cudnn.enabled = True
        torch.backends.cudnn.benchmark = True
        print("âœ… CuDNN enabled")
    except:
        print("âš ï¸ CuDNN not available")
    
    # 4. å†ç¢ºèª
    print(f"\nğŸ”„ After fix - CUDA available: {torch.cuda.is_available()}")
    
    if torch.cuda.is_available():
        print(f"ğŸ® Using GPU: {torch.cuda.get_device_name(0)}")
        return True
    else:
        print("âŒ GPU still not available")
        return False

def install_cuda_pytorch():
    """CUDAå¯¾å¿œPyTorchã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æŒ‡ç¤º"""
    print("\nğŸ“¥ CUDAå¯¾å¿œPyTorchã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãŒå¿…è¦ã§ã™")
    print("="*60)
    
    # CUDA versionç¢ºèª
    try:
        result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True)
        if result.returncode == 0:
            print("âœ… CUDA toolkit detected")
            # CUDA versionæŠ½å‡º
            for line in result.stdout.split('\n'):
                if 'release' in line.lower():
                    print(f"CUDA version: {line}")
                    break
        else:
            print("âŒ CUDA toolkit not found")
    except FileNotFoundError:
        print("âŒ nvcc not found")
    
    print("\nğŸ”§ è§£æ±ºæ–¹æ³•:")
    print("1. NVIDIAãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã‚’æœ€æ–°ç‰ˆã«æ›´æ–°")
    print("2. CUDA toolkitã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«")
    print("3. CUDAå¯¾å¿œPyTorchã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«:")
    print("   pip uninstall torch torchvision torchaudio")
    print("   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118")
    print("4. ã¾ãŸã¯ condaä½¿ç”¨:")
    print("   conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    print("ğŸš€ GPUç’°å¢ƒè¨ºæ–­ã¨ä¿®æ­£ã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
    print("="*60)
    
    # 1. ç¾åœ¨ã®çŠ¶æ³ç¢ºèª
    gpu_available = check_gpu_environment()
    
    # 2. ä¿®æ­£è©¦è¡Œ
    if not gpu_available:
        gpu_available = fix_gpu_environment()
    
    # 3. æœ€çµ‚ç¢ºèª
    if gpu_available:
        print("\nâœ… GPUç’°å¢ƒãŒæ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™ï¼")
        print("ğŸ® SHAPåˆ†æã‚’GPUã§å®Ÿè¡Œã§ãã¾ã™")
    else:
        print("\nâŒ GPUç’°å¢ƒã®ä¿®æ­£ã«å¤±æ•—ã—ã¾ã—ãŸ")
        install_cuda_pytorch()
    
    return gpu_available

if __name__ == "__main__":
    main()
