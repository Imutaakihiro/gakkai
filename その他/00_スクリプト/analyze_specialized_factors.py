#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç‰¹åŒ–è¦å› ã®è©³ç´°åˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import pandas as pd
import numpy as np

def analyze_specialized_factors():
    """ç‰¹åŒ–è¦å› ã®è©³ç´°åˆ†æ"""
    print("ğŸ” ç‰¹åŒ–è¦å› ã®è©³ç´°åˆ†æä¸­...")
    
    # ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
    sentiment_df = pd.read_csv('00_ã‚¹ã‚¯ãƒªãƒ—ãƒˆ/03_åˆ†æçµæœ/ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯SHAPåˆ†æ_BERTãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼_å…¨ãƒ‡ãƒ¼ã‚¿/æ„Ÿæƒ…ã‚¹ã‚³ã‚¢é‡è¦åº¦_è©³ç´°_å…¨ãƒ‡ãƒ¼ã‚¿.csv')
    course_df = pd.read_csv('00_ã‚¹ã‚¯ãƒªãƒ—ãƒˆ/03_åˆ†æçµæœ/ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯SHAPåˆ†æ_BERTãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼_å…¨ãƒ‡ãƒ¼ã‚¿/æˆæ¥­è©•ä¾¡ã‚¹ã‚³ã‚¢é‡è¦åº¦_è©³ç´°_å…¨ãƒ‡ãƒ¼ã‚¿.csv')
    
    # é–¾å€¤è¨­å®š
    threshold = 0.0001
    
    # é–¾å€¤ä»¥ä¸Šã®é‡è¦åº¦ã‚’æŒã¤èªå½™ã‚’æŠ½å‡º
    sentiment_high = sentiment_df[sentiment_df['importance'] >= threshold]['word'].tolist()
    course_high = course_df[course_df['importance'] >= threshold]['word'].tolist()
    
    # ç‰¹åŒ–è¦å› ã®æŠ½å‡º
    sentiment_only = set(sentiment_high) - set(course_high)
    course_only = set(course_high) - set(sentiment_high)
    
    print(f"\nğŸ“Š ç‰¹åŒ–è¦å› ã®çµ±è¨ˆ:")
    print(f"æ„Ÿæƒ…ç‰¹åŒ–è¦å› : {len(sentiment_only)}èªå½™")
    print(f"è©•ä¾¡ç‰¹åŒ–è¦å› : {len(course_only)}èªå½™")
    
    # æ„Ÿæƒ…ç‰¹åŒ–è¦å› ã®è©³ç´°åˆ†æ
    print(f"\nğŸ­ æ„Ÿæƒ…ç‰¹åŒ–è¦å›  (TOP10):")
    sentiment_specialized = []
    for word in sentiment_only:
        sentiment_imp = sentiment_df[sentiment_df['word'] == word]['importance'].iloc[0]
        course_imp = course_df[course_df['word'] == word]['importance'].iloc[0] if word in course_df['word'].values else 0
        sentiment_specialized.append({
            'word': word,
            'sentiment_importance': sentiment_imp,
            'course_importance': course_imp,
            'ratio': sentiment_imp / course_imp if course_imp > 0 else float('inf')
        })
    
    sentiment_specialized.sort(key=lambda x: x['sentiment_importance'], reverse=True)
    
    for i, item in enumerate(sentiment_specialized[:10], 1):
        print(f"{i:2d}. {item['word']:15s} | æ„Ÿæƒ…: {item['sentiment_importance']:.6f} | è©•ä¾¡: {item['course_importance']:.6f} | æ¯”ç‡: {item['ratio']:.1f}")
    
    # è©•ä¾¡ç‰¹åŒ–è¦å› ã®è©³ç´°åˆ†æ
    print(f"\nğŸ“š è©•ä¾¡ç‰¹åŒ–è¦å›  (TOP10):")
    course_specialized = []
    for word in course_only:
        course_imp = course_df[course_df['word'] == word]['importance'].iloc[0]
        sentiment_imp = sentiment_df[sentiment_df['word'] == word]['importance'].iloc[0] if word in sentiment_df['word'].values else 0
        course_specialized.append({
            'word': word,
            'sentiment_importance': sentiment_imp,
            'course_importance': course_imp,
            'ratio': course_imp / sentiment_imp if sentiment_imp > 0 else float('inf')
        })
    
    course_specialized.sort(key=lambda x: x['course_importance'], reverse=True)
    
    for i, item in enumerate(course_specialized[:10], 1):
        print(f"{i:2d}. {item['word']:15s} | æ„Ÿæƒ…: {item['sentiment_importance']:.6f} | è©•ä¾¡: {item['course_importance']:.6f} | æ¯”ç‡: {item['ratio']:.1f}")
    
    # ç‰¹åŒ–è¦å› ã®ç‰¹å¾´åˆ†æ
    print(f"\nğŸ” ç‰¹åŒ–è¦å› ã®ç‰¹å¾´åˆ†æ:")
    
    # æ„Ÿæƒ…ç‰¹åŒ–è¦å› ã®ç‰¹å¾´
    sentiment_words = [item['word'] for item in sentiment_specialized]
    print(f"\næ„Ÿæƒ…ç‰¹åŒ–è¦å› ã®ç‰¹å¾´:")
    print(f"- å­¦ç¿’å†…å®¹ãƒ»æŠ€è¡“è¦ç´ : {sum(1 for w in sentiment_words if any(x in w for x in ['ç´ å­', 'é›»å‹•', 'TA', 'ãƒ‡ãƒã‚¤ã‚¹', 'æ¼¢å­—']))}")
    print(f"- å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹: {sum(1 for w in sentiment_words if any(x in w for x in ['å­¦ã¶', 'æ›¸ã', 'çµ„ã‚€', 'å–ã‚Šçµ„ã‚€']))}")
    print(f"- å€‹äººçš„è¦ç´ : {sum(1 for w in sentiment_words if any(x in w for x in ['æ„Ÿè¬', 'ç”Ÿãç‰©', 'å‘¨è¾º']))}")
    
    # è©•ä¾¡ç‰¹åŒ–è¦å› ã®ç‰¹å¾´
    course_words = [item['word'] for item in course_specialized]
    print(f"\nè©•ä¾¡ç‰¹åŒ–è¦å› ã®ç‰¹å¾´:")
    print(f"- å­¦ç¿’æ–¹æ³•ãƒ»ã‚·ã‚¹ãƒ†ãƒ : {sum(1 for w in course_words if any(x in w for x in ['æ–¹å¼', 'åŸºç¤', 'ç¬¦å·', 'èª¿æ•´']))}")
    print(f"- å­¦ç¿’ç’°å¢ƒ: {sum(1 for w in course_words if any(x in w for x in ['äººæ', 'æˆ‘ã€…', 'åœ°çƒ', 'å½¢æˆ']))}")
    print(f"- è©•ä¾¡è¦ç´ : {sum(1 for w in course_words if any(x in w for x in ['é¸ã¶', 'ã¨ã‚‰', 'ä¸€æ¯']))}")
    
    return {
        'sentiment_specialized': sentiment_specialized,
        'course_specialized': course_specialized
    }

def create_specialized_factors_report(data):
    """ç‰¹åŒ–è¦å› ã®ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ"""
    print("\nğŸ“ ç‰¹åŒ–è¦å› ãƒ¬ãƒãƒ¼ãƒˆä½œæˆä¸­...")
    
    report = f"""# ç‰¹åŒ–è¦å› ã®è©³ç´°åˆ†æãƒ¬ãƒãƒ¼ãƒˆ

## ğŸ¯ åˆ†ææ¦‚è¦
- åˆ†ææ—¥æ™‚: 2025å¹´10æœˆ16æ—¥
- åˆ†æå¯¾è±¡: ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯å­¦ç¿’ã®ç‰¹åŒ–è¦å› 
- é–¾å€¤: 0.0001

## ğŸ“Š ç‰¹åŒ–è¦å› ã®çµ±è¨ˆ

### æ„Ÿæƒ…ç‰¹åŒ–è¦å›  (18èªå½™)
æ„Ÿæƒ…ã‚¹ã‚³ã‚¢ã®ã¿ã«å¼·ãå½±éŸ¿ã™ã‚‹è¦å› 

**TOP10:**
"""
    
    for i, item in enumerate(data['sentiment_specialized'][:10], 1):
        report += f"{i:2d}. **{item['word']}** - æ„Ÿæƒ…: {item['sentiment_importance']:.6f}, è©•ä¾¡: {item['course_importance']:.6f}\n"
    
    report += f"""
### è©•ä¾¡ç‰¹åŒ–è¦å›  (14èªå½™)
æˆæ¥­è©•ä¾¡ã‚¹ã‚³ã‚¢ã®ã¿ã«å¼·ãå½±éŸ¿ã™ã‚‹è¦å› 

**TOP10:**
"""
    
    for i, item in enumerate(data['course_specialized'][:10], 1):
        report += f"{i:2d}. **{item['word']}** - æ„Ÿæƒ…: {item['sentiment_importance']:.6f}, è©•ä¾¡: {item['course_importance']:.6f}\n"
    
    report += f"""
## ğŸ” ç‰¹åŒ–è¦å› ã®ç‰¹å¾´

### æ„Ÿæƒ…ç‰¹åŒ–è¦å› ã®ç‰¹å¾´
- **å­¦ç¿’å†…å®¹ãƒ»æŠ€è¡“è¦ç´ **: å…·ä½“çš„ãªå­¦ç¿’å†…å®¹ï¼ˆç´ å­ã€é›»å‹•ã€TAã€ãƒ‡ãƒã‚¤ã‚¹ãªã©ï¼‰
- **å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹**: å­¦ç¿’ã®æ–¹æ³•ãƒ»éç¨‹ï¼ˆå­¦ã¶ã€æ›¸ãã€çµ„ã‚€ãªã©ï¼‰
- **å€‹äººçš„è¦ç´ **: å€‹äººçš„ãªæ„Ÿæƒ…ãƒ»ä½“é¨“ï¼ˆæ„Ÿè¬ã€ç”Ÿãç‰©ã€å‘¨è¾ºãªã©ï¼‰

### è©•ä¾¡ç‰¹åŒ–è¦å› ã®ç‰¹å¾´
- **å­¦ç¿’æ–¹æ³•ãƒ»ã‚·ã‚¹ãƒ†ãƒ **: å­¦ç¿’ã®ä»•çµ„ã¿ãƒ»æ–¹æ³•ï¼ˆæ–¹å¼ã€åŸºç¤ã€ç¬¦å·ã€èª¿æ•´ãªã©ï¼‰
- **å­¦ç¿’ç’°å¢ƒ**: å­¦ç¿’ã‚’å–ã‚Šå·»ãç’°å¢ƒï¼ˆäººæã€æˆ‘ã€…ã€åœ°çƒã€å½¢æˆãªã©ï¼‰
- **è©•ä¾¡è¦ç´ **: è©•ä¾¡ã«é–¢é€£ã™ã‚‹è¦ç´ ï¼ˆé¸ã¶ã€ã¨ã‚‰ã€ä¸€æ¯ãªã©ï¼‰

## ğŸ¤ å­¦ä¼šç™ºè¡¨ã§ã®å›ç­”ä¾‹

### Q: ã€Œç‰¹åŒ–è¦å› ã£ã¦ãªã«ãŒã‚ã‚‹ã®ï¼Ÿã€

**A: ã€Œç‰¹åŒ–è¦å› ã¯å…¨ä½“ã®1%ç¨‹åº¦ã§ã™ãŒã€èˆˆå‘³æ·±ã„ç‰¹å¾´ãŒã‚ã‚Šã¾ã™ã€‚**

**æ„Ÿæƒ…ç‰¹åŒ–è¦å› ï¼ˆ18èªå½™ï¼‰ã¯ä¸»ã«ï¼š**
- **å­¦ç¿’å†…å®¹ãƒ»æŠ€è¡“è¦ç´ **ï¼ˆç´ å­ã€é›»å‹•ã€TAã€ãƒ‡ãƒã‚¤ã‚¹ï¼‰
- **å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹**ï¼ˆå­¦ã¶ã€æ›¸ãã€çµ„ã‚€ã€å–ã‚Šçµ„ã‚€ï¼‰
- **å€‹äººçš„è¦ç´ **ï¼ˆæ„Ÿè¬ã€ç”Ÿãç‰©ã€å‘¨è¾ºï¼‰

**è©•ä¾¡ç‰¹åŒ–è¦å› ï¼ˆ14èªå½™ï¼‰ã¯ä¸»ã«ï¼š**
- **å­¦ç¿’æ–¹æ³•ãƒ»ã‚·ã‚¹ãƒ†ãƒ **ï¼ˆæ–¹å¼ã€åŸºç¤ã€ç¬¦å·ã€èª¿æ•´ï¼‰
- **å­¦ç¿’ç’°å¢ƒ**ï¼ˆäººæã€æˆ‘ã€…ã€åœ°çƒã€å½¢æˆï¼‰
- **è©•ä¾¡è¦ç´ **ï¼ˆé¸ã¶ã€ã¨ã‚‰ã€ä¸€æ¯ï¼‰

**ã“ã‚Œã‚‰ã®ç‰¹åŒ–è¦å› ã¯ã€99%ã®å…±é€šè¦å› ã‚’è£œå®Œã™ã‚‹å½¹å‰²ã‚’æœãŸã—ã¦ãŠã‚Šã€å€‹åˆ¥ã®æ”¹å–„æˆ¦ç•¥ã«æ´»ç”¨ã§ãã¾ã™ã€‚ã€**

## ğŸ“ˆ æ•™è‚²æ”¹å–„ã¸ã®ç¤ºå”†

### 1. å…±é€šè¦å› ã¸ã®é›†ä¸­æŠ•è³‡
- 99%ã®è¦å› ã«é›†ä¸­ â†’ æœ€å¤§åŠ¹æœ

### 2. ç‰¹åŒ–è¦å› ã®å€‹åˆ¥å¯¾å¿œ
- æ„Ÿæƒ…å‘ä¸Š â†’ å­¦ç¿’å†…å®¹ãƒ»ãƒ—ãƒ­ã‚»ã‚¹ã®æ”¹å–„
- è©•ä¾¡å‘ä¸Š â†’ å­¦ç¿’æ–¹æ³•ãƒ»ç’°å¢ƒã®æ”¹å–„

### 3. çµ±åˆçš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
- å…±é€šè¦å›  + ç‰¹åŒ–è¦å› ã®çµ„ã¿åˆã‚ã›
- åŠ¹ç‡çš„ãªãƒªã‚½ãƒ¼ã‚¹é…åˆ†
"""
    
    # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
    with open('00_ã‚¹ã‚¯ãƒªãƒ—ãƒˆ/03_åˆ†æçµæœ/ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯SHAPåˆ†æ_BERTãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼_å…¨ãƒ‡ãƒ¼ã‚¿/ç‰¹åŒ–è¦å› è©³ç´°åˆ†æãƒ¬ãƒãƒ¼ãƒˆ.md', 'w', encoding='utf-8') as f:
        f.write(report)
    
    print("âœ… ç‰¹åŒ–è¦å› ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜å®Œäº†")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("=" * 60)
    print("ç‰¹åŒ–è¦å› ã®è©³ç´°åˆ†æ")
    print("=" * 60)
    
    # ç‰¹åŒ–è¦å› ã®åˆ†æ
    data = analyze_specialized_factors()
    
    # ãƒ¬ãƒãƒ¼ãƒˆã®ä½œæˆ
    create_specialized_factors_report(data)
    
    print("\nğŸ‰ ç‰¹åŒ–è¦å› ã®è©³ç´°åˆ†æå®Œäº†ï¼")
    print("ğŸ“ çµæœã¯ 00_ã‚¹ã‚¯ãƒªãƒ—ãƒˆ/03_åˆ†æçµæœ/ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯SHAPåˆ†æ_BERTãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼_å…¨ãƒ‡ãƒ¼ã‚¿ ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸ")

if __name__ == "__main__":
    main()
