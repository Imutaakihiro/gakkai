#!/usr/bin/env python3
"""
DirectMLç’°å¢ƒã®å‹•ä½œç¢ºèªã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import torch
import torch_directml as dml

def test_directml_setup():
    """DirectMLç’°å¢ƒã®å‹•ä½œç¢ºèª"""
    print("ğŸ” DirectMLç’°å¢ƒã®å‹•ä½œç¢ºèªã‚’é–‹å§‹...")
    print()
    
    # PyTorchæƒ…å ±
    print(f"ğŸ§  PyTorch version: {torch.__version__}")
    print(f"ğŸ§© DirectML available: {dml.is_available()}")
    
    if not dml.is_available():
        print("âŒ DirectMLãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
        return False
    
    # ãƒ‡ãƒã‚¤ã‚¹å–å¾—
    device = dml.device()
    print(f"ğŸš€ Using device: {device}")
    
    # ãƒ†ã‚¹ãƒˆæ¼”ç®—
    try:
        print("ğŸ§® DirectMLè¨ˆç®—ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œä¸­...")
        x = torch.randn(3, 3, device=device)
        y = torch.randn(3, 3, device=device)
        z = x @ y
        print(f"âœ… DirectMLè¨ˆç®—æˆåŠŸ: {z.device}")
        
        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ç¢ºèª
        print(f"ğŸ“Š GPU ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {torch.cuda.memory_allocated() / 1024**2:.2f} MB")
        
        return True
        
    except Exception as e:
        print(f"âŒ DirectMLè¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
        return False

if __name__ == "__main__":
    success = test_directml_setup()
    
    if success:
        print("\nğŸ‰ DirectMLç’°å¢ƒã®å‹•ä½œç¢ºèªå®Œäº†ï¼")
        print("å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆã§GPUãŒä½¿ç”¨å¯èƒ½ã§ã™ã€‚")
    else:
        print("\nâš ï¸ DirectMLç’°å¢ƒã«å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚")
        print("CPUã§å®Ÿè¡Œã™ã‚‹ã‹ã€ç’°å¢ƒã‚’å†ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
