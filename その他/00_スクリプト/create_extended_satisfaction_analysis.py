#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ‹¡å¼µæº€è¶³åº¦è¦å› åˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆ
SHAPåˆ†æçµæœã‹ã‚‰è©³ç´°ãªãƒ©ãƒ³ã‚­ãƒ³ã‚°ã¨ã‚«ãƒ†ã‚´ãƒªåˆ†æã‚’ä½œæˆ
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import japanize_matplotlib
from datetime import datetime
import os

def load_shap_data():
    """SHAPåˆ†æçµæœã‚’èª­ã¿è¾¼ã¿"""
    print("SHAPåˆ†æçµæœã‚’èª­ã¿è¾¼ã¿ä¸­...")
    
    # ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆå’æ¥­ç ”ç©¶ï¼ˆæ–°ï¼‰ï¼‰ã«ç§»å‹•
    script_dir = os.path.dirname(os.path.abspath(__file__))
    parent_dir = os.path.dirname(script_dir)
    os.chdir(parent_dir)
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    df = pd.read_csv('03_åˆ†æçµæœ/SHAPåˆ†æ/ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°5000ä»¶/word_importance_natural.csv')
    print(f"ãƒ‡ãƒ¼ã‚¿æ•°: {len(df)}èª")
    
    return df

def categorize_satisfaction_factors(df):
    """æº€è¶³åº¦è¦å› ã‚’ã‚«ãƒ†ã‚´ãƒªåˆ¥ã«åˆ†é¡ï¼ˆãƒã‚¸ãƒ†ã‚£ãƒ–ãƒ»ãƒã‚¬ãƒ†ã‚£ãƒ–ä¸¡æ–¹ï¼‰"""
    print("æº€è¶³åº¦è¦å› ã‚’ã‚«ãƒ†ã‚´ãƒªåˆ¥ã«åˆ†é¡ä¸­...")
    
    # ãƒã‚¸ãƒ†ã‚£ãƒ–ã‚«ãƒ†ã‚´ãƒªå®šç¾©
    positive_categories = {
        'ã‚ã‹ã‚Šã‚„ã™ã•': ['ã‚„ã™', 'åˆ†ã‹ã‚Š', 'ã‚ã‹ã‚Š', 'ç†è§£', 'èª¬æ˜', 'ä¸å¯§', 'è©³ã—ã', 'æ˜ç¢º'],
        'é¢ç™½ã•ãƒ»èˆˆå‘³': ['é¢ç™½', 'ãŠã‚‚ã—ã‚', 'é¢ç™½ã„', 'èˆˆå‘³', 'æ¥½ã—ã„', 'æ¥½ã—', 'æ¥½ã—ã‚ã‚‹', 'æ–°é®®', 'é£½ã'],
        'å­¦ç¿’åŠ¹æœ': ['å­¦', 'å­¦ã¶', 'å­¦ã³', 'ç¿’å¾—', 'å‘ä¸Š', 'æˆé•·', 'é”æˆ', 'åŠ¹æœ', 'ä¾¡å€¤', 'æ„ç¾©'],
        'å®Ÿç”¨æ€§': ['å®Ÿç”¨', 'å½¹ç«‹ã¤', 'å½¹', 'ä½¿ãˆã‚‹', 'æ´»ç”¨', 'æ´»ã‹ã—', 'ç”Ÿã‹ã—', 'å–ã‚Šå…¥ã‚Œ'],
        'æ„Ÿè¬ãƒ»æº€è¶³': ['è‰¯ã‹ã£ãŸ', 'ã‚ˆã‹ã£ãŸ', 'ã‚ã‚ŠãŒ', 'ã‚ã‚ŠãŒã¨ã†', 'æ„Ÿè¬', 'ãŠã‹ã’', 'å¬‰', 'å¥½ã'],
        'é”æˆæ„Ÿ': ['ã§ã', 'å‡ºæ¥', 'ã§ãã‚‹', 'å‡ºæ¥ã‚‹', 'é”æˆ', 'å¾—', 'å¾—ã‚‹', 'å–ã‚Œ', 'å¾—ç‚¹'],
        'äººé–“é–¢ä¿‚': ['ä»²è‰¯ã', 'ã¤ãªãŒã£', 'ã¤ãªãŒã‚Š', 'ç¹‹ãŒã£', 'ä¼š', 'ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³'],
        'å®‰å¿ƒæ„Ÿ': ['å®‰å¿ƒ', 'åŠ©', 'ã‚‚ã‚‰ãˆã‚‹', 'ãã‚Œã‚‹', 'å„ªã—ã„', 'æ°—åˆ†'],
        'æ·±ã„å­¦ã³': ['æ·±', 'æ·±ã‚ã‚‹', 'çŸ¥ã‚‹', 'çŸ¥ã‚Š', 'çŸ¥ã‚Œ', 'åˆ†ã‹ã£ãŸ', 'ã‚ã‹ã£ãŸ'],
        'æ©Ÿä¼šãƒ»ä½“é¨“': ['æ©Ÿä¼š', 'ãã£ã‹ã‘', 'ä½“é¨“', 'è§¦ã‚Œã‚‹', 'åˆ', 'éã”', 'ç”Ÿã']
    }
    
    # ãƒã‚¬ãƒ†ã‚£ãƒ–ã‚«ãƒ†ã‚´ãƒªå®šç¾©
    negative_categories = {
        'é›£ã—ã•ãƒ»è¤‡é›‘ã•': ['é›£', 'è¤‡é›‘', 'é›£ã—ã„', 'é›£ã—ã‹ã£ãŸ', 'è¤‡é›‘', 'å¤§', 'å¥¥', 'æ·±ã„'],
        'ä¸æº€ãƒ»å¤±æœ›': ['æ¬²ã—ã„', 'ã»ã—ã„', 'ã»ã—', 'ã¾ã˜', 'æœ€ä½', 'ã‚‚ã†', 'ç¨‹åº¦'],
        'è‹¦æ‰‹ãƒ»å›°é›£': ['è‹¦æ‰‹', 'å›°é›£', 'å¤§å¤‰', 'ç–²ã‚Œ', 'æ²¹', 'ä¸è¶³'],
        'æ”¹å–„è¦æ±‚': ['ç›´ã—', 'ç›´ã™', 'æ”¹å–„', 'ä¿®æ­£', 'å¤‰æ›´', 'ä¸‹ã•ã„', 'ãã ã•ã„'],
        'æ™‚é–“ãƒ»æœŸé™': ['æœŸé™', 'æœŸé–“', 'æ—©ã‚', 'é•·ã', 'é€”ä¸­', 'çµ‚ã‚ã‚‹'],
        'ç†è§£å›°é›£': ['åˆ†ã‹ã‚‰', 'ã‚ã‹ã‚‰', 'ä¸æ˜', 'æ›–æ˜§', 'æ··ä¹±', 'è¿·'],
        'é€€å±ˆãƒ»å˜èª¿': ['é€€å±ˆ', 'å˜èª¿', 'ã¤ã¾ã‚‰', 'é£½ã', 'ç¹°ã‚Šè¿”ã—', 'åŒã˜'],
        'è² æ‹…ãƒ»åœ§è¿«': ['è² æ‹…', 'åœ§è¿«', 'é‡ã„', 'å¤šã„', 'å¤§å¤‰', 'ã—ã‚“ã©'],
        'ä¸æº€è¶³': ['æ™®é€š', 'ã¾ã‚', 'ã¾ãš', 'å¾®å¦™', 'å¾®å¦™', 'ã‚¤ãƒã‚¤ãƒ'],
        'ãã®ä»–ãƒã‚¬ãƒ†ã‚£ãƒ–': ['æ¬ å¸­', 'æ€ ', 'çœŸé¢ç›®', 'å™¨å…·', 'ã‚·ãƒ¼ãƒˆ', 'ãƒãƒ¼ãƒˆ']
    }
    
    # ã‚«ãƒ†ã‚´ãƒªã‚’çµ±åˆ
    categories = {**positive_categories, **negative_categories}
    
    # ã‚«ãƒ†ã‚´ãƒªåˆ†é¡
    categorized_data = []
    
    for _, row in df.iterrows():
        word = row['natural'].strip()
        mean_shap = row['mean_shap']
        count = row['count']
        
        # ãƒã‚¸ãƒ†ã‚£ãƒ–ãƒ»ãƒã‚¬ãƒ†ã‚£ãƒ–åˆ¤å®š
        is_positive = mean_shap > 0
        sentiment_type = 'ãƒã‚¸ãƒ†ã‚£ãƒ–' if is_positive else 'ãƒã‚¬ãƒ†ã‚£ãƒ–'
        
        # ã‚«ãƒ†ã‚´ãƒªã‚’ç‰¹å®š
        category = 'ãã®ä»–'
        for cat_name, keywords in categories.items():
            if any(keyword in word for keyword in keywords):
                category = cat_name
                break
        
        categorized_data.append({
            'word': word,
            'mean_shap': mean_shap,
            'abs_mean_shap': row['abs_mean_shap'],
            'count': count,
            'category': category,
            'sentiment_type': sentiment_type
        })
    
    df_categorized = pd.DataFrame(categorized_data)
    
    # ã‚«ãƒ†ã‚´ãƒªåˆ¥çµ±è¨ˆ
    category_stats = df_categorized.groupby('category').agg({
        'mean_shap': ['mean', 'max', 'count'],
        'abs_mean_shap': 'mean',
        'count': 'sum'
    }).round(4)
    
    print(f"ã‚«ãƒ†ã‚´ãƒªæ•°: {len(category_stats)}")
    for category in category_stats.index:
        count = category_stats.loc[category, ('mean_shap', 'count')]
        print(f"  {category}: {count}èª")
    
    return df_categorized, category_stats

def create_extended_rankings(df_categorized, output_dir):
    """æ‹¡å¼µãƒ©ãƒ³ã‚­ãƒ³ã‚°ã®ä½œæˆï¼ˆãƒã‚¸ãƒ†ã‚£ãƒ–ãƒ»ãƒã‚¬ãƒ†ã‚£ãƒ–ä¸¡æ–¹ï¼‰"""
    print(f"æ‹¡å¼µãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’ä½œæˆä¸­... ({output_dir})")
    
    os.makedirs(output_dir, exist_ok=True)
    
    # ãƒã‚¸ãƒ†ã‚£ãƒ–ãƒ»ãƒã‚¬ãƒ†ã‚£ãƒ–åˆ†é›¢
    df_positive = df_categorized[df_categorized['sentiment_type'] == 'ãƒã‚¸ãƒ†ã‚£ãƒ–']
    df_negative = df_categorized[df_categorized['sentiment_type'] == 'ãƒã‚¬ãƒ†ã‚£ãƒ–']
    
    # 1. ãƒã‚¸ãƒ†ã‚£ãƒ–TOP50ãƒ©ãƒ³ã‚­ãƒ³ã‚°
    top50_positive = df_positive.nlargest(50, 'mean_shap')
    
    plt.figure(figsize=(14, 16))
    y_pos = range(len(top50_positive))
    plt.barh(y_pos, top50_positive['mean_shap'], color='lightgreen')
    plt.yticks(y_pos, [f"{row['word']} ({row['category']})" for _, row in top50_positive.iterrows()])
    plt.xlabel('SHAPå€¤')
    plt.title('ãƒã‚¸ãƒ†ã‚£ãƒ–æº€è¶³åº¦è¦å›  TOP50\n(ã‚«ãƒ†ã‚´ãƒªåˆ¥åˆ†é¡)')
    plt.gca().invert_yaxis()
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'positive_satisfaction_factors_top50.png'), dpi=300, bbox_inches='tight')
    plt.close()
    
    # 2. ãƒã‚¬ãƒ†ã‚£ãƒ–TOP50ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆçµ¶å¯¾å€¤ã§ã‚½ãƒ¼ãƒˆï¼‰
    top50_negative = df_negative.nlargest(50, 'abs_mean_shap')
    
    plt.figure(figsize=(14, 16))
    y_pos = range(len(top50_negative))
    plt.barh(y_pos, top50_negative['mean_shap'], color='lightcoral')
    plt.yticks(y_pos, [f"{row['word']} ({row['category']})" for _, row in top50_negative.iterrows()])
    plt.xlabel('SHAPå€¤')
    plt.title('ãƒã‚¬ãƒ†ã‚£ãƒ–æº€è¶³åº¦è¦å›  TOP50\n(ã‚«ãƒ†ã‚´ãƒªåˆ¥åˆ†é¡)')
    plt.gca().invert_yaxis()
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'negative_satisfaction_factors_top50.png'), dpi=300, bbox_inches='tight')
    plt.close()
    
    # 3. çµ±åˆTOP100ãƒ©ãƒ³ã‚­ãƒ³ã‚°
    top100 = df_categorized.nlargest(100, 'abs_mean_shap')
    
    plt.figure(figsize=(16, 20))
    y_pos = range(len(top100))
    colors = ['lightgreen' if row['sentiment_type'] == 'ãƒã‚¸ãƒ†ã‚£ãƒ–' else 'lightcoral' 
              for _, row in top100.iterrows()]
    plt.barh(y_pos, top100['mean_shap'], color=colors)
    plt.yticks(y_pos, [f"{row['word']} ({row['category']})" for _, row in top100.iterrows()])
    plt.xlabel('SHAPå€¤')
    plt.title('æº€è¶³åº¦è¦å›  TOP100\n(ãƒã‚¸ãƒ†ã‚£ãƒ–ãƒ»ãƒã‚¬ãƒ†ã‚£ãƒ–çµ±åˆ)')
    plt.gca().invert_yaxis()
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'satisfaction_factors_top100_combined.png'), dpi=300, bbox_inches='tight')
    plt.close()
    
    # 3. ã‚«ãƒ†ã‚´ãƒªåˆ¥ãƒ©ãƒ³ã‚­ãƒ³ã‚°
    fig, axes = plt.subplots(2, 5, figsize=(20, 12))
    axes = axes.flatten()
    
    categories = df_categorized['category'].unique()
    
    for i, category in enumerate(categories[:10]):  # ãƒˆãƒƒãƒ—10ã‚«ãƒ†ã‚´ãƒª
        cat_data = df_categorized[df_categorized['category'] == category].nlargest(10, 'mean_shap')
        
        if len(cat_data) > 0:
            y_pos = range(len(cat_data))
            axes[i].barh(y_pos, cat_data['mean_shap'], color='skyblue')
            axes[i].set_yticks(y_pos)
            axes[i].set_yticklabels(cat_data['word'])
            axes[i].set_xlabel('SHAPå€¤')
            axes[i].set_title(f'{category}\n({len(cat_data)}èª)')
            axes[i].invert_yaxis()
    
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'satisfaction_factors_by_category.png'), dpi=300, bbox_inches='tight')
    plt.close()
    
    # 4. ã‚«ãƒ†ã‚´ãƒªåˆ¥çµ±è¨ˆ
    plt.figure(figsize=(12, 8))
    category_means = df_categorized.groupby('category')['mean_shap'].mean().sort_values(ascending=True)
    
    plt.barh(range(len(category_means)), category_means.values, color='lightcoral')
    plt.yticks(range(len(category_means)), category_means.index)
    plt.xlabel('å¹³å‡SHAPå€¤')
    plt.title('ã‚«ãƒ†ã‚´ãƒªåˆ¥å¹³å‡æº€è¶³åº¦')
    plt.gca().invert_yaxis()
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'satisfaction_by_category.png'), dpi=300, bbox_inches='tight')
    plt.close()
    
    return top50_positive, top50_negative, top100

def create_detailed_report(df_categorized, top50_positive, top50_negative, top100, category_stats, output_dir):
    """è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã®ä½œæˆï¼ˆãƒã‚¸ãƒ†ã‚£ãƒ–ãƒ»ãƒã‚¬ãƒ†ã‚£ãƒ–ä¸¡æ–¹ï¼‰"""
    print(f"è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆä¸­... ({output_dir})")
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    report_path = os.path.join(output_dir, f'extended_satisfaction_analysis_{timestamp}.md')
    
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write("# æ‹¡å¼µæº€è¶³åº¦è¦å› åˆ†æãƒ¬ãƒãƒ¼ãƒˆï¼ˆãƒã‚¸ãƒ†ã‚£ãƒ–ãƒ»ãƒã‚¬ãƒ†ã‚£ãƒ–çµ±åˆï¼‰\n\n")
        f.write(f"**åˆ†ææ—¥æ™‚:** {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}\n\n")
        
        # ãƒ‡ãƒ¼ã‚¿æ¦‚è¦
        f.write("## ğŸ“Š ãƒ‡ãƒ¼ã‚¿æ¦‚è¦\n\n")
        f.write(f"- **åˆ†æå¯¾è±¡èªæ•°:** {len(df_categorized)}èª\n")
        f.write(f"- **ãƒã‚¸ãƒ†ã‚£ãƒ–èªæ•°:** {len(df_categorized[df_categorized['sentiment_type'] == 'ãƒã‚¸ãƒ†ã‚£ãƒ–'])}èª\n")
        f.write(f"- **ãƒã‚¬ãƒ†ã‚£ãƒ–èªæ•°:** {len(df_categorized[df_categorized['sentiment_type'] == 'ãƒã‚¬ãƒ†ã‚£ãƒ–'])}èª\n")
        f.write(f"- **ã‚«ãƒ†ã‚´ãƒªæ•°:** {len(category_stats)}ã‚«ãƒ†ã‚´ãƒª\n")
        f.write(f"- **ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹:** SHAPåˆ†æçµæœï¼ˆ5,000ä»¶ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼‰\n\n")
        
        # ãƒã‚¸ãƒ†ã‚£ãƒ–TOP50ãƒ©ãƒ³ã‚­ãƒ³ã‚°
        f.write("## ğŸ† ãƒã‚¸ãƒ†ã‚£ãƒ–æº€è¶³åº¦è¦å›  TOP50\n\n")
        f.write("| é †ä½ | é‡è¦èª | ã‚«ãƒ†ã‚´ãƒª | SHAPå€¤ | å‡ºç¾å›æ•° |\n")
        f.write("|------|--------|----------|--------|----------|\n")
        
        for i, (_, row) in enumerate(top50_positive.iterrows(), 1):
            f.write(f"| {i} | {row['word']} | {row['category']} | {row['mean_shap']:.4f} | {row['count']} |\n")
        
        f.write("\n")
        
        # ãƒã‚¬ãƒ†ã‚£ãƒ–TOP50ãƒ©ãƒ³ã‚­ãƒ³ã‚°
        f.write("## âš ï¸ ãƒã‚¬ãƒ†ã‚£ãƒ–æº€è¶³åº¦è¦å›  TOP50\n\n")
        f.write("| é †ä½ | é‡è¦èª | ã‚«ãƒ†ã‚´ãƒª | SHAPå€¤ | å‡ºç¾å›æ•° |\n")
        f.write("|------|--------|----------|--------|----------|\n")
        
        for i, (_, row) in enumerate(top50_negative.iterrows(), 1):
            f.write(f"| {i} | {row['word']} | {row['category']} | {row['mean_shap']:.4f} | {row['count']} |\n")
        
        f.write("\n")
        
        # çµ±åˆTOP100ãƒ©ãƒ³ã‚­ãƒ³ã‚°
        f.write("## ğŸ¥‡ æº€è¶³åº¦è¦å›  TOP100ï¼ˆçµ±åˆï¼‰\n\n")
        f.write("| é †ä½ | é‡è¦èª | ã‚«ãƒ†ã‚´ãƒª | æ„Ÿæƒ… | SHAPå€¤ | å‡ºç¾å›æ•° |\n")
        f.write("|------|--------|----------|------|--------|----------|\n")
        
        for i, (_, row) in enumerate(top100.iterrows(), 1):
            sentiment_emoji = "ğŸ˜Š" if row['sentiment_type'] == 'ãƒã‚¸ãƒ†ã‚£ãƒ–' else "ğŸ˜"
            f.write(f"| {i} | {row['word']} | {row['category']} | {sentiment_emoji} | {row['mean_shap']:.4f} | {row['count']} |\n")
        
        f.write("\n")
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥åˆ†æ
        f.write("## ğŸ“ˆ ã‚«ãƒ†ã‚´ãƒªåˆ¥åˆ†æ\n\n")
        f.write("| ã‚«ãƒ†ã‚´ãƒª | å¹³å‡SHAPå€¤ | æœ€å¤§SHAPå€¤ | èªæ•° | ç·å‡ºç¾å›æ•° |\n")
        f.write("|----------|------------|------------|------|------------|\n")
        
        for category in category_stats.index:
            mean_shap = category_stats.loc[category, ('mean_shap', 'mean')]
            max_shap = category_stats.loc[category, ('mean_shap', 'max')]
            word_count = category_stats.loc[category, ('mean_shap', 'count')]
            total_count = category_stats.loc[category, ('count', 'sum')]
            
            f.write(f"| {category} | {mean_shap:.4f} | {max_shap:.4f} | {word_count} | {total_count} |\n")
        
        f.write("\n")
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥è©³ç´°
        f.write("## ğŸ” ã‚«ãƒ†ã‚´ãƒªåˆ¥è©³ç´°åˆ†æ\n\n")
        
        for category in category_stats.index:
            cat_data = df_categorized[df_categorized['category'] == category].nlargest(10, 'mean_shap')
            
            if len(cat_data) > 0:
                f.write(f"### {category}\n\n")
                f.write("| é †ä½ | é‡è¦èª | SHAPå€¤ | å‡ºç¾å›æ•° |\n")
                f.write("|------|--------|--------|----------|\n")
                
                for i, (_, row) in enumerate(cat_data.iterrows(), 1):
                    f.write(f"| {i} | {row['word']} | {row['mean_shap']:.4f} | {row['count']} |\n")
                
                f.write("\n")
        
        # çµ±è¨ˆæƒ…å ±
        f.write("## ğŸ“Š çµ±è¨ˆæƒ…å ±\n\n")
        f.write(f"- **æœ€é«˜SHAPå€¤:** {df_categorized['mean_shap'].max():.4f}\n")
        f.write(f"- **å¹³å‡SHAPå€¤:** {df_categorized['mean_shap'].mean():.4f}\n")
        f.write(f"- **æ¨™æº–åå·®:** {df_categorized['mean_shap'].std():.4f}\n")
        f.write(f"- **ç·å‡ºç¾å›æ•°:** {df_categorized['count'].sum():,}\n")
        f.write(f"- **ãƒ¦ãƒ‹ãƒ¼ã‚¯èªæ•°:** {len(df_categorized)}\n\n")
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥çµ±è¨ˆ
        f.write("## ğŸ¯ ã‚«ãƒ†ã‚´ãƒªåˆ¥çµ±è¨ˆ\n\n")
        for category in category_stats.index:
            mean_shap = category_stats.loc[category, ('mean_shap', 'mean')]
            word_count = category_stats.loc[category, ('mean_shap', 'count')]
            f.write(f"- **{category}:** å¹³å‡SHAPå€¤ {mean_shap:.4f}, {word_count}èª\n")
        
        f.write("\n")
        
        # æ”¹å–„æŒ‡é‡
        f.write("## ğŸ’¡ æˆæ¥­æ”¹å–„æŒ‡é‡ï¼ˆã‚«ãƒ†ã‚´ãƒªåˆ¥ï¼‰\n\n")
        
        improvement_guidance = {
            'ã‚ã‹ã‚Šã‚„ã™ã•': 'å°‚é–€ç”¨èªã®ä¸å¯§ãªèª¬æ˜ã€æ®µéšçš„ãªèª¬æ˜ã€è¦–è¦šçš„è³‡æ–™ã®æ´»ç”¨',
            'é¢ç™½ã•ãƒ»èˆˆå‘³': 'å®Ÿä¾‹ãƒ»äº‹ä¾‹ã®ç´¹ä»‹ã€æœ€æ–°ã®è©±é¡Œãƒ»ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®æ´»ç”¨ã€ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªæˆæ¥­',
            'å­¦ç¿’åŠ¹æœ': 'å­¦ç¿’ç›®æ¨™ã®æ˜ç¢ºåŒ–ã€æ®µéšçš„ãªé”æˆæ„Ÿã€ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®å……å®Ÿ',
            'å®Ÿç”¨æ€§': 'å®Ÿè·µçš„ãªæ¼”ç¿’ã€å®Ÿéš›ã®å ´é¢ã§ã®æ´»ç”¨ä¾‹ã€å¿œç”¨èª²é¡Œã®æä¾›',
            'æ„Ÿè¬ãƒ»æº€è¶³': 'å­¦ç”Ÿã®æ„è¦‹ã‚’å°Šé‡ã€ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®å……å®Ÿã€å€‹åˆ¥æŒ‡å°ã®æ©Ÿä¼š',
            'é”æˆæ„Ÿ': 'é©åˆ‡ãªé›£æ˜“åº¦è¨­å®šã€æ®µéšçš„ãªç›®æ¨™ã€æˆæœã®å¯è¦–åŒ–',
            'äººé–“é–¢ä¿‚': 'ã‚°ãƒ«ãƒ¼ãƒ—ãƒ¯ãƒ¼ã‚¯ã€ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³ã€å­¦ç”Ÿé–“ã®äº¤æµä¿ƒé€²',
            'å®‰å¿ƒæ„Ÿ': 'è³ªå•ã—ã‚„ã™ã„ç’°å¢ƒã€å€‹åˆ¥æŒ‡å°ã€ã‚µãƒãƒ¼ãƒˆä½“åˆ¶ã®å……å®Ÿ',
            'æ·±ã„å­¦ã³': 'æ¢ç©¶çš„ãªèª²é¡Œã€é–¢é€£åˆ†é‡ã¨ã®é€£æºã€å¤šè§’çš„ãªè¦–ç‚¹',
            'æ©Ÿä¼šãƒ»ä½“é¨“': 'å®Ÿä½“é¨“ã®æ©Ÿä¼šã€å¤–éƒ¨è¬›å¸«ã€ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒ¯ãƒ¼ã‚¯'
        }
        
        for category, guidance in improvement_guidance.items():
            if category in category_stats.index:
                f.write(f"### {category}\n")
                f.write(f"{guidance}\n\n")
    
    print(f"è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜: {report_path}")

def save_extended_data(df_categorized, top50_positive, top50_negative, top100, category_stats, output_dir):
    """æ‹¡å¼µãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜ï¼ˆãƒã‚¸ãƒ†ã‚£ãƒ–ãƒ»ãƒã‚¬ãƒ†ã‚£ãƒ–ä¸¡æ–¹ï¼‰"""
    print(f"æ‹¡å¼µãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ä¸­... ({output_dir})")
    
    # ãƒã‚¸ãƒ†ã‚£ãƒ–TOP50ã‚’CSVã§ä¿å­˜
    top50_positive.to_csv(os.path.join(output_dir, 'positive_satisfaction_factors_top50.csv'), 
                         index=False, encoding='utf-8-sig')
    
    # ãƒã‚¬ãƒ†ã‚£ãƒ–TOP50ã‚’CSVã§ä¿å­˜
    top50_negative.to_csv(os.path.join(output_dir, 'negative_satisfaction_factors_top50.csv'), 
                         index=False, encoding='utf-8-sig')
    
    # çµ±åˆTOP100ã‚’CSVã§ä¿å­˜
    top100.to_csv(os.path.join(output_dir, 'satisfaction_factors_top100_combined.csv'), 
                  index=False, encoding='utf-8-sig')
    
    # ã‚«ãƒ†ã‚´ãƒªåˆ¥ãƒ‡ãƒ¼ã‚¿ã‚’CSVã§ä¿å­˜
    df_categorized.to_csv(os.path.join(output_dir, 'satisfaction_factors_categorized.csv'), 
                         index=False, encoding='utf-8-sig')
    
    # ã‚«ãƒ†ã‚´ãƒªåˆ¥çµ±è¨ˆã‚’CSVã§ä¿å­˜
    category_stats.to_csv(os.path.join(output_dir, 'category_statistics.csv'), 
                         encoding='utf-8-sig')
    
    print("æ‹¡å¼µãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜å®Œäº†")

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("=" * 60)
    print("æ‹¡å¼µæº€è¶³åº¦è¦å› åˆ†æ")
    print("=" * 60)
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    df = load_shap_data()
    
    # ã‚«ãƒ†ã‚´ãƒªåˆ†é¡
    df_categorized, category_stats = categorize_satisfaction_factors(df)
    
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    output_dir = '03_åˆ†æçµæœ/æ‹¡å¼µæº€è¶³åº¦è¦å› åˆ†æ'
    os.makedirs(output_dir, exist_ok=True)
    
    # æ‹¡å¼µãƒ©ãƒ³ã‚­ãƒ³ã‚°ä½œæˆ
    top50_positive, top50_negative, top100 = create_extended_rankings(df_categorized, output_dir)
    
    # è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ
    create_detailed_report(df_categorized, top50_positive, top50_negative, top100, category_stats, output_dir)
    
    # ãƒ‡ãƒ¼ã‚¿ä¿å­˜
    save_extended_data(df_categorized, top50_positive, top50_negative, top100, category_stats, output_dir)
    
    print("\n" + "=" * 60)
    print("æ‹¡å¼µåˆ†æå®Œäº†ï¼")
    print("=" * 60)
    print(f"çµæœã¯ {output_dir} ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸ")
    print(f"ãƒã‚¸ãƒ†ã‚£ãƒ–TOP50: {len(top50_positive)}èª")
    print(f"ãƒã‚¬ãƒ†ã‚£ãƒ–TOP50: {len(top50_negative)}èª")
    print(f"çµ±åˆTOP100: {len(top100)}èª")
    print(f"ã‚«ãƒ†ã‚´ãƒªæ•°: {len(category_stats)}")

if __name__ == "__main__":
    main()
